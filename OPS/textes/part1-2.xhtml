<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" xml:lang="fr" lang="fr">
  <head>
    <title> Ingénieurs, hackers : naissance d’une culture</title>
    <link rel="stylesheet" href="../styles/stylesheet.css" type="text/css" />
  </head>
  <body epub:type="bodymatter chapter">
    <h2 id="part1-2" class="titre-chapitre">
      2. Ingénieurs, <i lang="en" xml:lang="en" class="droit">hackers</i> : naissance d’une culture
    </h2>
    <p class="signature">Christophe <span class="auteur">Masutti</span></p>

    <nav epub:type="bodymatter toc" class="epub-toc">
      <ol>
        <li><a href="#part1-2.1">2.1 À propos d’ordinateurs et de temps partagé</a></li>
        <li><a href="#part1-2.2">2.2 Moufettes et canard sauvages</a></li>
        <li><a href="#part1-2.3">2.3 Le travail <i lang="en" xml:lang="en">hacker</i></a></li>
        <li><a href="#part1-2.4">2.4 Réseau</a></li>
        <li><a href="#part1-2.5">2.5 Une contre-culture ?</a></li>
      </ol>
    </nav>

    <p> Au début des années 1960, lorsque l’<abbr>IBM</abbr>/360 fut prêt à être produit et vendu à plusieurs centaines d’exemplaires, il était fort présomptueux d’affirmer que le marché était lui aussi prêt à accueillir ces nouvelles machines qui tiraient parti de plusieurs innovations matérielles assez peu connues. Néanmoins, ces machines étaient présentes et leur création relevait davantage d’une démonstration des capacités d’innovation des ingénieurs d’<abbr>IBM</abbr> que de l’analyse d’un besoin concrètement exprimé dans les secteurs industriels ou de services. Nous verrons dans cet article à quel point l’organisation de l’activité d’ingénierie a modelé l’industrie informatique. Cela tient au fait que l’informatique des décennies 1950 et 1960 ne fut pas seulement un « âge d’or » pour la recherche et le développement, mais un moment où se cristallisèrent socialement un ensemble de pratiques et de représentations à priori hétérogènes. Ces dernières déterminèrent nombre d’innovations concernant le partage de l’information, l’ingénierie logicielle, les modèles d’organisation des entreprises, l’utilisation des machines et leurs trajectoires. </p>
    <p> Dans ce contexte, l’adage suivant lequel « la nécessité crée l’innovation » est quelque peu désuet. Dans bien des cas, dans l’histoire de l’informatique moderne et particulièrement dans l’évolution des programmes et des langages de programmation, la « nécessité » n’est que peu ou pas exprimée socialement. Elle le fut par exemple dans le cas de la cybernétique pour la création du langage LISP, aujourd’hui l’un des plus anciens langages de haut niveau inventé par John McCarthy en 1958. Ce langage répondait à un besoin : dépasser la limite des capacités humaines pour se représenter des programmes de plus en plus complexes. Or, l’évolution de ce langage et les multiples branches qui en découlèrent, y compris l’invention des Machines LISP spécialement conçues, furent davantage le produit des efforts de « rivalités » entre <i lang="en" xml:lang="en">hackers</i> motivés par « l’émulation procurée par l’habileté technique, caractéristique de la culture <i lang="en" xml:lang="en">hacker</i> », pour reprendre les termes de G. Steel et R. Gabriel analysant l’évolution de LISP depuis sa création jusqu’aux années 1990 <a epub:type="noteref" href="#note_1" id="ref_1"> <sup>[1]</sup></a>. </p>
    <p> Cet article vise à explorer les fondements de la culture <i lang="en" xml:lang="en">hacker</i> et à expliquer comment, à partir d’un modèle d’organisation, des principes d’action ont pu voir le jour, se réclamant de l’éthique <i lang="en" xml:lang="en">hacker</i> et aujourd’hui exprimés plus prosaïquement par le « mouvement du Libre ». </p>
    <p> Nous resterons attachés à la période des deux décennies 1950 et 1960 où nous verrons d’une part comment le concept de <i lang="en" xml:lang="en">timesharing </i>a « révolutionné » les représentations de l’ingénierie, en particulier dans le secteur industriel. D’autre part, nous tâcherons de déterminer quels furent les modèles d’organisation, hérités de l’industrie, qui entrèrent en jeu lors de l’émergence de l’ingénierie de programmation (<i lang="en" xml:lang="en">software engineering</i>). Cette analyse nous conduira à nous interroger sur le <i lang="en" xml:lang="en">hacker</i> en tant qu’archétype de l’ingénieur-programmeur, dont les pratiques (ou l’<i lang="la" xml:lang="la">ethos</i>) qu’il véhicule impliquent en permanence un positionnement par rapport aux enjeux du changement technologique dont il est à la fois concepteur et utilisateur.</p>

    <section epub:type="bodymatter subchapter">
      <h3 id="part1-2.1">2.1 À propos d’ordinateurs et de temps partagé</h3>
      <p> En février et mars 1957, un ingénieur issu de l’aéronavale, Robert (Bob) Bemer, publie un article en deux parties dans la revue <i lang="en" xml:lang="en">Automatic Control</i>, qu’il intitule « Qu’est-ce qu’un ingénieur doit savoir à propos de la programmation informatique ? » <a epub:type="noteref" href="#note_2" id="ref_2"> <sup>[2]</sup></a>. Bemer est un acteur célèbre dans le monde informatique. Il travailla notamment avec Grace Hopper sur le langage COBOL et a contribué significativement aux spécifications de l’ASCII, ce qui lui vaut d’être parfois surnommé le « père de l’ASCII ». Dans cet article, Bemer se penche sur le changement des pratiques qu’implique l’apparition de l’informatique dans le monde de l’ingénierie. Pour lui, un ingénieur ne doit pas seulement concevoir des modèles et attendre qu’un programmeur professionnel crée les programmes qui permettent de faire de multiples calculs et les entre dans la machine. L’ingénieur doit au contraire connaître la programmation car, de cette manière, il peut créer et améliorer des langages de programmation adaptés aux besoins exacts de sa spécialité d’ingénierie. Cela, il doit savoir le faire sur des machines (à temps) partagées(é), c’est-à-dire ces gros ordinateurs <i lang="en" xml:lang="en">mainframe</i> très chers dont la particularité est de permettre à plusieurs utilisateurs d’avoir accès au temps de calcul. </p>
      <p> Le premier avantage de cette mutualisation de la machine est de partager le coût du temps de calcul, compte tenu de l’investissement financier qu’elle représente. Le second avantage est que, compte tenu des innovations de ces machines, la création de nouveaux langages de programmation permet de rendre de plus en plus efficaces leurs applications à l’ingénierie. La programmation étant elle-même une forme d’ingénierie, les apprentissages de ces langages se font de manière coopérative, entre les utilisateurs. De ce partage des langages (qui s’exprime surtout par le partage de compilateurs sans cesse améliorés), on apprend donc que l’organisation de la communauté et la structure des machines (ici, les ordinateurs à temps partagé), favorisent l’émergence des formes de coopérations qui transcendent les différents domaines de l’ingénierie où l’informatique peut s’appliquer : Bemer cite alors 80 secteurs classés dans 7 domaines (aéronautique, chimie, mathématiques, électricité, physique (nucléaire), statistique, divers) où la programmation est censée devenir un savoir-faire incontournable. </p>
      <p> En réalité, Bemer se positionnait en visionnaire. En 1957, les ordinateurs à temps partagés qui pouvaient être ainsi utilisés n’existaient encore que dans l’esprit de certains programmeurs de génie, parmi lesquels Bob Bemer et John McCarthy, l’inventeur du langage LISP et, justement, du premier système d’exploitation à temps partagé. Il est certain qu’une page décisive était en train de se tourner. Bemer avait exprimé les besoins et la manière d’y répondre. À peine deux ans plus tard, une rencontre entre industriels et chercheurs du <abbr lang="en" xml:lang="en">MIT</abbr>, à l’occasion d’une démonstration de LISP <a epub:type="noteref" href="#note_3" id="ref_3"> <sup>[3]</sup></a>, donna le jour au concept de <i lang="en" xml:lang="en">computer utility</i> : la possibilité de livrer des services en séparant les ressources matérielles et le calcul. Sur la base de cet argument, des fonds soulevés auprès de la National Science Foundation permirent à l’équipe de McCarthy de créer en 1961 le premier système d’exploitation (ou environnement) pour le temps partagé : <i lang="en" xml:lang="en" class="droit">Compatible Time-Sharing System</i> (<abbr>CTSS</abbr>). C’est sur la base de cette nouveauté pour l’esprit que représentait un langage informatique autant qu’à travers la vision d’un monde de machines au service de l’innovation technologique que naquirent plus tard les premières sociétés de services fournissant aux institutions comme aux particuliers des accès sur des machines distantes pouvant supporter plusieurs utilisateurs simultanés. </p>
      <p> Les épisodes que nous venons de raconter illustrent combien l’histoire de l’informatique moderne ne saurait se contenter de retracer les grandes étapes des créations de machines et de langages, d’un point de vue finaliste, comme pour arriver enfin à la définition contemporaine d’un ordinateur. Selon l’historien Paul E. Ceruzzi, s’intéresser à l’histoire des ordinateurs consiste d’abord à admettre que la définition même d’un ordinateur implique une période durant laquelle il est possible de faire une histoire des techniques informatiques. Un ordinateur sert à calculer. De ce point de vue, l’histoire des outils techniques servant au calcul peut nous emmener loin dans le temps, au moins pour couvrir la période séparant les premiers bouliers-compteurs (manuel) à la Pascaline (automatisme). Il en va différemment pour les ordinateurs, que Ceruzzi nomme <i lang="en" xml:lang="en">modern computer </i>et définit ainsi : </p>
      <blockquote>
        <p> Il s’agit d’un système : un dispositif hiérarchique composé de matériel informatique (<i lang="en" xml:lang="en" class="droit">hardware</i>) et de logiciels (<i lang="en" xml:lang="en" class="droit">software</i>). Quiconque travaille sur ce système à un certain niveau n’a pas de visibilité sur ce qui se passe dans les autres niveaux. Quant aux plus hauts de ces derniers, ils sont constitués de logiciels – par définition, les éléments qui n’ont pas de forme tangible mais que l’on peut au mieux décrire comme étant les méthodes d’organisation. <a epub:type="noteref" href="#note_4" id="ref_4"> <sup>[4]</sup></a></p>
      </blockquote>
      <p> La complexité des ordinateurs, leurs représentations, leurs agencements et les connaissances nécessaires à leur élaboration et leur utilisation, toutes ces facettes justifient qu’une histoire cohérente des ordinateurs modernes ne peut se réduire à l’addition de plusieurs histoires comme celle de l’électronique, de l’ingénierie, du calcul informatique, ou de l’électricité, prenant en compte l’objet « ordinateur » comme une innovation parmi d’autres. En somme, l’histoire des ordinateurs ne saurait se contenter du seul point de vue de l’histoire informatique analysant une production issue de l’ingénierie et de la technique. Dans ce dernier domaine, en effet, il serait difficile de réduire les facteurs décisifs de l’innovation à la seule dynamique de l’offre et de la demande. </p>
      <p> L’analyse politique permet de rapprocher les innovations en techniques de l’information avec la demande, par exemple, en matière de politique de défense et d’armement. En revanche, toujours en suivant cet exemple, comment faire le lien entre les politiques publiques encourageant massivement les centres de recherches et l’accroissement de nouvelles machines, notamment durant la période de la Guerre froide ? La compétition internationale en matière de puissance de calcul, dont le Plan Calcul lancé en 1966 en France par le Général De Gaulle, démontre la recherche d’indépendance par rapport aux autres pays plus novateurs (après le rachat de Bull par <i lang="en" xml:lang="en" class="droit">General Electric</i>), mais justifie-t-il à lui seul le développement industriel français dans le domaine des circuits intégrés ? Là encore, ce serait faire un raccourci que de ne considérer les résultats de la recherche et de l’ingénierie uniquement comme les fruits de la volonté politique. Il existe en effet une foule de facteurs sociaux déterminant l’innovation dont souvent la volonté politique ne fait que formaliser rétrospectivement les moyens humains et cognitifs mobilisés. </p>
      <p> Il en va ainsi du développement des ordinateurs à temps partagé. Le fait d’avoir besoin de pouvoir accéder à plusieurs, via des terminaux d’accès, aux ressources d’une seule machine peut être interprété de plusieurs manières : </p>
      <ul>
        <li>La réponse à un besoin d’une population grandissante de chercheurs contraints à effectuer des calculs toujours plus complexes sur des machines coûteuses et ne pouvant pas assurer la charge de plus d’un utilisateur à la fois. Il s’agirait donc d’optimiser l’accès aux ressources. </li>
        <li>Une solution envisagée de manière à pouvoir optimiser le développement de nouveaux langages informatiques de haut niveau, comme le langage LISP, mais aussi tous les langages servant à modéliser dans différents secteurs d’ingénierie. </li>
        <li>Enfin, il est possible aussi de voir dans l’émergence des ordinateurs à temps partagé le résultat de plusieurs années de recherche en matière d’ingénierie logicielle visant à créer des systèmes d’exploitation capables de gérer efficacement les accès (comme ce fut le cas du projet MAC, qui donna le système Multics, successeur de <abbr>CTSS</abbr>, et qui deviendra encore plus tard Unix). Une linéarité est alors envisagée entre la recherche, les applications et l’industrie, constituant généralement l’interprétation la plus facile et la plus connue de l’histoire des ordinateurs à temps partagé. </li>
      </ul>
      <p> Peut-on établir une hiérarchie stricte entre ces facteurs ? Aucunement. Le fait est que les déterminants sociaux de telles innovations sont complètement imbriqués : les chercheurs ne font pas que chercher, il faut qu’ils financent leurs projets de recherche et produisent l’expertise nécessaire à la décision publique en répondant à des appels d’offres ; les spécialistes de l’ingénierie logicielle, les programmeurs, ne font pas que s’adapter au matériel existant, ils produisent eux-mêmes des savoirs-faire et créent une demande matérielle, quant aux politiques publiques et aux institutions, elles formalisent dans une logique de projets et de financement les orientations pré-existantes ou, sur la base de l’expertise des chercheurs et des ingénieurs, accentuent des orientations méritant des développements plus poussés. </p>
      <p> Le terme « révolution » employé dans plusieurs domaines de l’informatique moderne est souvent utilisé pour expliquer une convergence entre un besoin et l’émergence d’une réponse technique qui s’impose dans de multiples voire tous les domaines d’activités. Il s’agit d’une construction sociale, pour reprendre l’expression consacrée. Mais cette image est quelque peu faussée. Par exemple, l’anthropologue Bryan Pfaffenberger <a epub:type="noteref" href="#note_5" id="ref_5"> <sup>[5]</sup></a> montre que ce sont les industriels qui ont construit le mythe de l’utilité révolutionnaire de l’ordinateur personnel afin d’en lancer le développement et la vente à grande échelle et définir les contours du marché. </p>
      <p> La « révolution » informatique est donc beaucoup plus théorique. Elle s’est exprimée à partir du moment où naquirent de nouveaux apprentissages issus de l’application de l’informatique aux activités humaines et, donc, un nouveau champ épistémologique à explorer sur la base d’un rapport nouveau entre calcul et information. Loin d’être uniquement l’émergence de nouvelles technologies censées optimiser les activités existantes, ce changement s’est aussi exprimé d’un point de vue social, car il fut le vecteur de nouveaux rapports organisationnels. À propos des « acteurs » (sociaux) de la révolution informatique, Pfaffenberger – nous le suivons sur ce point dans le domaine de la sociologie des sciences et des techniques – préfère de loin utiliser non pas le terme d’acteur-réseau que l’on trouve chez Michel Callon et Bruno Latour, mais celui mieux choisi d’ingénieur hétérogène (défini par John Law), c’est-à-dire un acteur qui ne crée pas seulement une nouvelle technologie, mais qui définit un nouveau cadre du rôle social, des représentations et des valeurs de cette technologie et des ingénieurs qui l’emploient et la diffusent. C’est exactement ce que Janet Abbate propose dans un plaidoyer pour une étude <abbr>STS</abbr> (<i lang="en" xml:lang="en" class="droit">Science and Technology Studies</i>) de l’histoire d’Internet : « Lorsqu’on observe à la fois les créateurs et les utilisateurs de matériels et de logiciels, on s’aperçoit que l’infrastructure et la culture ont amorcé une fusion » <a epub:type="noteref" href="#note_6" id="ref_6"> <sup>[6]</sup></a>. Or, dans l’histoire de la révolution informatique, cette fusion est triple car elle engage à la fois l’innovation technologique, le cadre culturel et la figure de l’ingénieur hétérogène qui incarne cette culture et qui fut autrement nommé <i lang="en" xml:lang="en">hacker</i>, c’est-à-dire un programmeur dont le génie ne réside pas seulement dans la qualité de son travail mais aussi dans sa manière de traduire un ensemble de valeurs de la sphère informatique à la sphère sociale : le partage de l’information, l’esprit d’innovation (d’amélioration), les libertés d’usages de machines, l’idée qu’un « progrès technique » est aussi un « progrès social » dans la mesure où tout le monde peut y contribuer et en être bénéficiaire. </p>
      <p> Tout cela suppose un modèle d’organisation dans le travail de ces ingénieurs hétérogènes, un modèle qui n’est pas apparu ex-nihilo, mais, comme nous allons le voir, est issu du monde industriel, et même hérité des infrastructures informatiques, comme le percevait brillamment Bob Bemer. </p>
    </section>

    <section epub:type="bodymatter subchapter">
      <h3 id="part1-2.2">2.2 Moufettes et canard sauvages</h3>
      <p> À partir de la fin de la Seconde Guerre mondiale, on voit apparaître dans l’industrie aéronautique américaine l’expression <i lang="en" xml:lang="en">skunk works </i>(littéralement, travaux de moufette). Il s’agit de désigner le travail d’équipes formées d’ingénieurs, souvent cooptés par leurs pairs en fonction des besoins et des compétences, travaillant sur des projets non-officiels, c’est-à-dire soit des projets secrets relevant de la Défense nationale, soit des projets hautement novateurs dont le débouché n’est pas clairement défini par l’entreprise mais disposant de suffisamment d’éléments probants pour faire l’objet d’un investissement <a epub:type="noteref" href="#note_7" id="ref_7"> <sup>[7]</sup></a>. Les <i lang="en" xml:lang="en">skunk works</i> ont emprunté leur appellation officielle au sein de l’entreprise américaine <i lang="en" xml:lang="en" class="droit">Lockheed Martin</i> (anciennement <i lang="en" xml:lang="en" class="droit">Lockheed Corporation</i>, qui fusionna en 1994 avec Martin Marietta), aujourd’hui la principale firme de production d’armement de la Défense américaine. Si cette appellation remonte à l’immédiate après-guerre, notamment dans le domaine des avions longs courriers, elle fourbit ses armes durant la Guerre froide, dans le contexte très concurrentiel de la course à l’armement, où l’aéronautique militaire américaine se devait de produire des avions inédits tels le <i lang="en" xml:lang="en" class="droit">Lockheed U-2</i>, un avion de reconnaissance à très grand rayon d’action, fleuron de l’innovation technologique américaine. Dans ce contexte où l’espionnage industriel était une préoccupation majeure <a epub:type="noteref" href="#note_8" id="ref_8"> <sup>[8]</sup></a>, la <i lang="en" xml:lang="en" class="droit">Lockheed Corporation</i> se devait de conserver secrets certains développements quitte à ne pas élaborer de stratégie claire pouvant révéler des intentions sur la création de prototypes. Les <i lang="en" xml:lang="en">skunk works</i> permettaient à la fois d’allier la créativité, en favorisant des pratiques communautaires d’échanges de connaissances et d’expériences, et la protection industrielle, en permettant des développements n’obéissant à priori à aucune stratégie explicite et ne répondant à aucun appel d’offres gouvernemental (du moins pas officiellement, à l’image du projet XP-80, premier prototype d’avion à réaction). L’expression fut néanmoins connue dans différents milieux industriels et employée jusqu’à nos jours, de manière courante, bien que <i lang="en" xml:lang="en" class="droit">Lockheed Martin</i> ait déposé cette marque (avec son logo, une moufette) comme étant l’autre nom de son antenne de recherche et développement, l’<i lang="en" xml:lang="en" class="droit">Advanced Development Programs</i> (<abbr>ADP</abbr>). </p>
      <p> Les <i lang="en" xml:lang="en">skunk works </i>sont donc des dispositifs d’organisation en ingénierie <a epub:type="noteref" href="#note_9" id="ref_9"> <sup>[9]</sup></a> alliant quatre principes : la vitesse de conception, l’identification de l’individu au groupe dont il fait partie et avec qui il partage une vision positive des activités en cours, la reconnaissance d’un leader (non coopté mais institué en tant que tel par la firme et sur lequel repose la responsabilité des travaux), la motivation suscitée non par l’impératif de réussite de la mise en œuvre mais par le travail lui-même porteur de changement et de nouveauté. Ainsi, les <i lang="en" xml:lang="en">skunk works</i> constituent des groupes de travail avec une forte cohésion jouant le rôle de laboratoires de recherche mais dont les larges marges de manœuvre sont stratégiquement établies par la firme. Pour autant, l’autonomie n’est pas synonyme d’indépendance : l’évaluation des travaux s’établit sur le long terme au vu des apports théoriques et pratiques du groupe de travail à la firme. En cas d’insatisfaction, un tel groupe peut être dissous ou les travaux en cours peuvent être réorientés en vue d’atteindre des objectifs différents. En retour, ce groupe opérant en dehors de l’organisation « normale » de l’entreprise est enclin à se soustraire aux décisions des gestionnaires ou, du moins, ne pas tenir compte des contraintes imposées à l’entreprise car elles ne font pas partie du cœur de métier. </p>
      <p> Ainsi, après la Seconde Guerre, les impératifs économiques aidant, les modèles d’organisation industriels étaient parfois en mesure de réserver de tels espaces de créativité en favorisant des groupes d’hommes de métier à exercer leur art tout en encadrant non pas leur travail mais les conditions d’exercice, et tout en pariant sur les futures opportunités en termes de production qu’un tel groupe était capable de fournir. Ce type d’organisation était-il pour autant entré dans les mœurs générales ? Comme nous allons le voir avec la firme <abbr>IBM</abbr>, il est certain que les secteurs industriels de hautes technologies avaient adopté ce modèle. Le fait de permettre à un salarié de consacrer la totalité ou une partie de son temps de travail à la réalisation de projets coopératifs était une manière d’envisager l’innovation. </p>
      <p> Dans le cadre de la recherche universitaire, en revanche, il serait difficile d’établir une comparaison, dans la mesure où tout projet est par définition un <i lang="en" xml:lang="en">skunk work</i>, néanmoins, quelques similarités peuvent être établies notamment dans le cadre du projet Arpanet. Si, comme nous le verrons plus loin, nous concevons ce dernier comme une accumulation de technologies et d’améliorations par les utilisateurs, la coopération s’était établie sous la forme d’un encouragement général provenant à la fois des institutions participant au projet mais aussi par la cohésion du groupe de collaborateurs œuvrant pour différents programmes de recherche mais retrouvant dans ce projet de réseau les motivations de leur créativité. </p>
      <p> Comme le montrent les <i lang="en" xml:lang="en">skunk works</i>, la représentation du travail d’ingénierie et de recherche dans le domaine des hautes technologies d’après-guerre incluait ces espaces de métiers dont les <i lang="en" xml:lang="en">hackers</i> des années 1960-1970 tels que les décrits Steven Levy <a epub:type="noteref" href="#note_10" id="ref_10"> <sup>[10]</sup></a> ne constituent qu’une forme, déjà ancienne, appliquée au domaine de l’informatique et tout particulièrement de la programmation. Dans ce dernier domaine, certaines entreprises avaient aussi développé leur propre modèle, ce qui fut en particulier le cas chez <abbr>IBM</abbr>. </p>
      <p> <abbr>IBM</abbr> (International Business Machines) est une entreprise remarquable sur bien des points. Fondée en 1911 par Charles R. Flint, elle fusionna, sous le nom de <i lang="en" xml:lang="en" class="droit">Computing Tabulating Recording Company</i>, les entreprises et productions qui constituaient sans doute l’avant-garde de la révolution technologique de la seconde moitié du <abbr title="vingtième" class="chiffre-romain">xx<sup>e</sup></abbr> siècle : la calculatrice de mesure de Julius Pitrap, l’enregistreur / pointeuse d’Alexander Dey et William Bundy et surtout la machine à statistiques à cartes perforées de Herman Hollerith <a epub:type="noteref" href="#note_11" id="ref_11"> <sup>[11]</sup></a>. En cela, cette fusion préfigurait ce qui allait devenir une véritable culture d’entreprise chez <abbr>IBM</abbr> : rassembler les nouveautés et assembler les compétences <a epub:type="noteref" href="#note_12" id="ref_12"> <sup>[12]</sup></a>. C’est sous la direction de Thomas J. Watson Jr., qui succéda à son père à la tête de l’entreprise en 1952 et jusqu’en 1971, qu’<abbr>IBM</abbr> s’offrit une place de choix dans l’industrie informatique, confirmée par l’apparition de l’<abbr>IBM</abbr> System/360 en 1964, une véritable gamme de machines, tournant sur le même logiciel avec les mêmes périphériques. Or, pour les mêmes raisons que dans l’industrie aéronautique, le secteur hautement concurrentiel des ordinateurs <i lang="en" xml:lang="en">mainframe </i>nécessitait des groupes de travail plus ou moins secrets <a epub:type="noteref" href="#note_13" id="ref_13"> <sup>[13]</sup></a>, dont l’objectif était de cristalliser les caractéristiques parfois anarchiques du processus de créativité, et rendre ce dernier <em>compatible </em>avec la structure commerciale de l’entreprise. </p>
      <p> À la différence des <i lang="en" xml:lang="en">skunk works</i>, cependant, l’objectif voulu et décrit par T. Watson Jr. <a epub:type="noteref" href="#note_14" id="ref_14"> <sup>[14]</sup></a> consistait à encadrer les travaux de groupes auto-formés, par affinité, identifiés parmi la population des ingénieurs-programmeurs en fonction de leur potentiel novateur. En d’autres termes, le rôle du manager était de capter l’apport théorique et technique des groupes de collaborateurs constitués d’esthètes de la programmation et de l’électronique, motivés par l’idée de « changer le monde ». Cette manière de manager la créativité en informatique était ce que T. Watson Jr. appelait « dresser les canards sauvages » (<i lang="en" xml:lang="en">wild ducks</i>), et cette expression perdura chez <abbr>IBM</abbr> tant elle représentait parfaitement la culture de l’entreprise, très proche du <abbr lang="en" xml:lang="en">MIT</abbr> et des groupes de <i lang="en" xml:lang="en">hackers</i> du monde universitaire : </p>
      <blockquote>
        <p> Chez <abbr>IBM</abbr>, nous mentionnons souvent notre besoin d’avoir des <em>canards sauvages</em>. La morale est tirée d’un récit du philosophe danois Soren Kierkegaard, à propos d’un homme qui se met à nourrir les canards sauvages migrant vers le sud à chaque automne. Après quelque temps, certains de ces canards ne prirent plus la peine de voler vers le sud et passèrent l’hiver au Danemark, où l’homme les nourrissait. Puis ils volèrent de moins en moins. Après trois ou quatre années, il devinrent si gros et paresseux qu’ils avaient toutes les peines du monde à voler. Kierkegaard attira l’attention sur ce point : vous pouvez apprivoiser des canards sauvages, mais vous ne rendrez jamais sauvages des canard apprivoisés. On pourrait ajouter aussi qu’un canard, une fois apprivoisé, n’ira plus jamais nulle part. Nous sommes convaincus que toute entreprise a besoin de ses canards sauvages. Et chez <abbr>IBM</abbr>, nous n’essayons pas de les apprivoiser. <a epub:type="noteref" href="#note_15" id="ref_15"> <sup>[15]</sup></a></p>
      </blockquote>
      <p> Au début des années 1950, le besoin de machines était conséquent sur un marché au départ inexistant. Pour prendre l’exemple de l’<abbr>IBM</abbr> 701, sorti en 1952, 19 exemplaires furent fournis pour des universités, l’industrie aéronautique et les institutions gouvernementales. Pourtant, dès la sortie de l’<abbr>IBM</abbr> 701, les cadres commerciaux d’<abbr>IBM</abbr> s’aperçurent que les besoins concernaient à priori tous les domaines de l’ingénierie : du calcul des trajectoires de fusées à la conceptualisation d’infrastructures de transports, ou encore les bureaux gouvernementaux de statistiques et les banques, en somme tout ce qui nécessitait de lourds calculs sur un marché auparavant monopolisé par Univac, la première firme en mesure de vendre de telles machines (le premier <i lang="en" xml:lang="en" class="droit">UNIVersal Automatic Computer <abbr class="chiffre-romain" title="one">i</abbr> </i>fut produit en 1951). En produisant le supercalculateur <abbr>IBM</abbr> 701, en réponse à un appel d’offres de la Défense américaine, <abbr>IBM</abbr> remporta brillamment la première manche sur le marché et collabora avec la firme <i lang="en" xml:lang="en" class="droit">Engineering Research Associates</i> (<abbr>ERA</abbr>), une entreprise auparavant subventionnée par l’<i lang="en" xml:lang="en" class="droit">U.S. Navy</i> afin d’effectuer des recherches en cryptographie et qui était à l’origine de l’<abbr>UNIVAC</abbr> au sein de <i lang="en" xml:lang="en" class="droit">Remington Rand</i>. Cette firme, qui s’était spécialisée en techniques de stockage d’information, avait largement amélioré le dispositif de mémoire à tambour magnétique, inventé au début des années 1930 par Gustav Tauschek, notamment en augmentant la densité et en réduisant le temps d’accès à la mémoire <a epub:type="noteref" href="#note_16" id="ref_16"> <sup>[16]</sup></a>. </p>
      <p> Grâce à l’appropriation de ces récentes technologies, <abbr>IBM</abbr> se trouvait en position de force pour s’avancer sur un marché plus étendu que celui de l’<abbr>IBM</abbr> 701. C’est à partir du moment où ce positionnement stratégique fut décidé que les <i lang="en" xml:lang="en">wild ducks</i> entrèrent en scène. L’objectif était de produire en série des ordinateurs utilisant l’électronique et le magnétisme, possédant une grande rapidité de calcul et des capacités de mémoire étendues, mais pour un coût abordable. En revanche personne chez <abbr>IBM</abbr>, et encore moins T. Watson Jr., n’était en mesure de savoir quels étaient exactement (techniquement) les besoins auxquels devaient répondre de telles machines, si ce n’est de permettre d’effectuer des calculs et stocker des informations. L’ingénieur de métier chez <abbr>IBM</abbr> devait s’accommoder d’une décision managériale qui n’intégrait pas les contraintes <em>client</em> de mise en œuvre. Si bien que ce qui fut assez longtemps reproché à <abbr>IBM</abbr>, à savoir un marketing agressif au détriment d’une véritable ambition d’équiper les clients avec des systèmes ultra-performants, fut exactement le résultat de cette volonté de couvrir un marché aux contours encore très flous. </p> <p> En 1953, un an après l’arrivée de T. Watson Jr. à la tête de l’entreprise, l’<abbr>IBM</abbr> 650 (Magnetic Drum Calculator) fut mis sur le marché. Bien qu’il ne fît pas sensation du point de vue de ses capacités techniques, il fut le premier ordinateur vendu en masse (1800 exemplaires furent vendus ou loués en deux années de production), le moins cher du marché (un demi million de dollars contre un million pour la gamme Univac), et aussi le plus petit (capable de tenir dans une seule pièce). </p>
      <p> Alliance entre plusieurs technologies existantes et éprouvées par ailleurs, l’<abbr>IBM</abbr> 650 correspondait parfaitement à la culture <abbr>IBM</abbr> et à celle des <i lang="en" xml:lang="en">wild ducks</i>. En effet, même après les premiers exemplaires produits, les cibles marketing n’étaient pas des plus évidentes. <abbr>IBM</abbr> cherchant toujours à diviser ses cibles entre les entreprises et la recherche, il allait de soi que l’<abbr>IBM</abbr> 650, petit (proportionnellement aux autres machines sur le marché), modulaire, facile à programmer et permettant un accès rapide aux données (moins de 2,4 msec), passait devant les plus gros ordinateurs pour s’adapter à un usage dans le secteur industriel ou bancaire. Pourtant, ce furent les universités les plus demandeuses, pour des raisons à la fois commerciales et pratiques : une réduction importante leur était habituellement accordée par <abbr>IBM</abbr> en échange de cours sur la gestion de données ou en informatique générale ; par ailleurs, l’<abbr>IBM</abbr> 650 fournissant un des accès les plus rapides aux données, permettait par conséquent une plus grande rapidité dans la programmation et limitait les temps d’attente, un avantage clairement revendiqué par la population des programmeurs universitaires. Ainsi, <abbr>IBM</abbr> et ses <i lang="en" xml:lang="en">wild ducks</i> avaient fait un pari de développement basé non pas sur des cibles marketing ou sur un défi technologique, mais sur une certaine vision de la société : « on » avait forcément besoin de machines permettant un stockage optimal de l’information pour un coût raisonnable, ce qui en retour devrait se traduire par une expression plus précise des besoins. L’important n’était pas de savoir qui et pour quels usages, mais de développer en un maximum d’exemplaires des machines reposant sur les deux piliers de l’informatique moderne : rapidité et stockage. Tout l’aspect créatif du projet se situait dans l’amélioration des technologies existantes et dans une vision positive de l’utilité sociale de l’informatique. </p>
      <p> Cela n’allait évidemment pas sans critiques, dont la principale concernait le choix de la technologie de mémoire utilisée dans l’<abbr>IBM</abbr> 650, à savoir une mémoire à tambour, alors même que les mémoires à tores (magnétique) de ferrite (<i lang="en" xml:lang="en">core memory</i>) étaient en passe de devenir le principal support des machines produites jusqu’aux années 1970. En effet, la même année 1953 où sortait sur le marché l’<abbr>IBM</abbr> 650, des systèmes à mémoire magnétique furent installés sur deux machines déjà assez anciennes : l’ENIAC et le <i lang="en" xml:lang="en" class="droit">Whirlwind</i>. Concernant l’ENIAC (<i lang="en" xml:lang="en" class="droit">Electronic Numerical Integrator and Computer</i>), conçu entre 1943 et 1946 à l’université de Pennsylvanie par John P. Eckert et John W. Mauchly, il était destiné à effectuer des calculs balistiques suite à une demande militaire. L’utilisation d’un nouveau système de mémoire augmentait certes les capacités d’accès mais avait un impact bien moindre que sur le <i lang="en" xml:lang="en" class="droit">Whirlwind</i>, conçu expressément en 1947 pour permettre un accès très rapide à la mémoire. </p>
      <p> L’objectif du <i lang="en" xml:lang="en" class="droit">Whirlwind</i>, conçu par Jay Forrester au Lincoln Laboratory (<abbr lang="en" xml:lang="en">MIT</abbr>), répondait là encore à une demande militaire consistant à créer un simulateur de vol, c’est-à-dire un système capable de traiter des données changeantes, d’où le besoin crucial de réduire le temps d’accès aux données. L’intégration d’un dispositif de mémoire à tores de ferrite fut une telle réussite que le Whirlwind fut surnommé Whirlwind II, puisqu’il avait plus que doublé sa vitesse de calcul (plus de 40.000 instructions par secondes). L’impact fut tel dans la communauté des programmeurs que les ingénieurs d’<abbr>IBM</abbr> n’attendirent pas la sortie de l’<abbr>IBM</abbr> 650 pour travailler sur ce dispositif et répondirent déjà en 1952 à l’appel d’offres du SAGE (<i lang="en" xml:lang="en" class="droit">Semi-Automatic Ground Environment – U.S. Air Force</i>) et du <i lang="en" xml:lang="en" class="droit">Lincoln Laboratory</i> pour produire un équipement hybride (mêlant mémoire à tores magnétiques et mémoire à tambours magnétiques) en une trentaine d’exemplaires <a epub:type="noteref" href="#note_17" id="ref_17"> <sup>[17]</sup></a>. Cela était d’autant plus difficile pour <abbr>IBM</abbr> d’éviter les critiques affirmant que la firme préférait développer et vendre plutôt que d’attendre un ou deux ans de développement supplémentaires et vendre une machine « grand public » en évitant les mémoires à tambours. On le devine aisément, ces critiques provenaient des chercheurs du <abbr lang="en" xml:lang="en">MIT</abbr> et d’Harvard qui, justement, avaient une visibilité assez complète des possibilités informatiques de la mémoire à tores magnétique, en particulier la non-volatilité de la mémoire (plus besoin d’une alimentation électrique spécifique ou d’un dispositif mécanique pour accéder à une mémoire). C’est dans le cadre de ses coopérations avec le <i lang="en" xml:lang="en" class="droit">Lincoln Laboratory</i> et le SAGE que <abbr>IBM</abbr> pu ainsi garantir sa présence sur le marché des ordinateurs rapides, notamment face à <i lang="en" xml:lang="en" class="droit">Remington Rand</i> (UNIVAC) <a epub:type="noteref" href="#note_18" id="ref_18"> <sup>[18]</sup></a>. </p>
      <p> <i lang="en" xml:lang="en">Skunk works </i>et <i lang="en" xml:lang="en">wild ducks </i>formaient donc des communautés d’ingénieurs dont l’organisation – basée sur un management global de groupes non hiérarchisés mais motivés par un projet commun – était courante dans le secteur des hautes technologies, et entrait la plupart du temps en interaction avec le monde académique. Les <i lang="en" xml:lang="en">hackers</i> du <abbr lang="en" xml:lang="en">MIT</abbr> des années 1960-1970 ne constituaient finalement qu’une résonance universitaire du management de la créativité d’ingénierie des firmes. Cette résonance s’explique bien entendu parce que nous nous situons dans un régime de coopération utilitaire entre ingénierie et recherche, entre les firmes et les universités. L’exemple d’<abbr>IBM</abbr> illustre bien, dès la création de cette entreprise, à quel point les liens avec le <abbr lang="en" xml:lang="en">MIT</abbr> étaient profonds et historiques (Herman Hollerith y enseignait la mécanographie), de même qu’avec tous les autres laboratoires d’informatique où <abbr>IBM</abbr> – tout comme DEC, Remington Rand, Burrough, et bien d’autres – allait puiser des enseignements et des apports théoriques en échange de tarifs préférentiels voire de dons de machines. Dans le cas du <abbr lang="en" xml:lang="en">MIT</abbr>, le positionnement stratégique d’<abbr>IBM</abbr> était aussi géographique : le <i lang="en" xml:lang="en" class="droit">Cambridge Research Lab</i>, une succursale du <i lang="en" xml:lang="en" class="droit">T.J. Watson Research Center</i> d’<abbr>IBM</abbr>, se trouve en fait à mi-chemin entre la banque Charles River et le campus central du <abbr lang="en" xml:lang="en">MIT</abbr>. C’est là que fut inventé en 1967 l’<abbr>IBM</abbr> 360/67, doté de mémoire virtuelle et fonctionnant en temps partagé avec <abbr>TSS</abbr> (<i lang="en" xml:lang="en" class="droit">Time-Sharing System</i>), une adaptation directe du système <i lang="en" xml:lang="en" class="droit"><abbr>CTSS</abbr>/Multics</i> (nous reviendrons plus loin sur ce système) pour les ordinateurs <i lang="en" xml:lang="en">mainframe</i> d’<abbr>IBM</abbr>. Mais cette résonance s’explique aussi parce que, comme les <i lang="en" xml:lang="en">wild ducks</i> d’<abbr>IBM</abbr>, les <i lang="en" xml:lang="en">hackers</i> du <i lang="en" xml:lang="en" class="droit">Tech Model Railroad Club</i> et du <abbr lang="en" xml:lang="en">MIT</abbr> (pour ne prendre que cet exemple dont il va être question par la suite), étaient convaincus que l’informatique avait un impact positif sur la société par le biais de l’avancement des sciences : les sciences du langage, de la communication mais aussi la cybernétique naissante, en particulier grâce à la programmation et l’apparition des langages de programmation dont LISP est une illustration flamboyante d’abstraction logique et d’applications directes à l’ingénierie (ce qui fut concrétisé plus tard par la création de machines LISP). </p>
      <p> Ces modèles d’organisation et d’innovation constituèrent un héritage à la fin des années 1960, proprement émulé par les interrelations entre l’industrie et la recherche universitaire. Cela donna lieu à la construction d’un archétype <i lang="en" xml:lang="en">hacker</i>, dont il faut dès à présent déterminer les contours pour comprendre le passage du groupe d’acteurs novateurs à l’idée de communautés de programmeurs. </p>
    </section>

    <section epub:type="bodymatter subchapter">
      <h3 id="part1-2.3">2.3 Le travail <i lang="en" xml:lang="en">hacker</i></h3>
      <p> Le célèbre livre de Steven Levy, <i lang="en" xml:lang="en">Hackers. Heroes of the Computer Revolution</i>, qui a connu jusqu’à aujourd’hui plusieurs rééditions, peut être considéré comme la première référence où le processus de cristallisation de l’« esprit <i lang="en" xml:lang="en">hacker</i> » se révèle de manière claire et documentée, à partir de nombreuses <i lang="en" xml:lang="en" class="droit">interviews</i> <a epub:type="noteref" href="#note_19" id="ref_19"> <sup>[19]</sup></a>. Que nous apprend cet ouvrage ? Écrit par un journaliste au début des années 1980, il obéit d’abord à un projet de constitution d’une mémoire des « pionniers » de l’informatique aux États-Unis, et en particulier l’identification d’une communauté de programmeurs dont les activités ont donné lieu à différents types d’innovations techniques dans la conception d’ordinateurs et de logiciels qui constituèrent une part significative de la « révolution informatique » de la fin des années 1950 au début des années 1980. L’analyse de Steven Lévy repose sur l’identification de plusieurs archétypes présents dans cette communauté de programmeurs se reconnaissant, d’après leurs propres propos, comme des <i lang="en" xml:lang="en">hackers</i>. </p>
      <p> Le terme lui-même est assez vague et sa signification est compréhensible avant tout à partir du contexte où il est possible de parler d’une <em>culture </em><i lang="en" xml:lang="en" class="droit">hacker</i>, non pas en fonction des productions issues de leur secteur d’activités en ingénierie (l’informatique des deux décennies 1960 et 1970 est un domaine où se mêlent les spécialités en programmation, réseau et électronique), mais en fonction des pratiques qui rassemblent les <i lang="en" xml:lang="en">hackers</i> en un groupe structuré : l’éthique <i lang="en" xml:lang="en">hacker</i>. L’éthique dont il est question ici est à entendre comme un ensemble de principes régulateurs de l’action, une normalisation de l’activité professionnelle dont les racines tacitement reconnues par la communauté se retrouvent, selon S. Lévy, dans les activités du <i lang="en" xml:lang="en" class="droit">Tech Model Railroad Club</i> (<abbr>TMRC</abbr>), le club de modélisme ferroviaire du <abbr lang="en" xml:lang="en">MIT</abbr>, en particulier durant les années 1958-1959, lorsque les membres chargés de l’élaboration des circuits électriques et des signaux avaient un accès, à des fins de calcul, au TX-0, le premier ordinateur à transistor (<i lang="en" xml:lang="en" class="droit">Transistorized Experimental computer zero</i>) issu du <i lang="en" xml:lang="en" class="droit">Lincoln Laboratory</i> du <abbr lang="en" xml:lang="en">MIT</abbr>. </p>
      <p> S. Lévy montre combien ce club joue, pour prendre une métaphore photographique, le rôle d’un révélateur de pratiques d’ingénierie basées exactement sur les principes managériaux de l’industrie (<i lang="en" xml:lang="en">wild ducks</i>) mais de manière auto-gérée : des bidouilleurs de talent à l’esprit potache qui trouvaient dans ce club un lieu en dehors des contraintes administratives et académiques pour exercer leurs talents dans une logique de projet et partager des connaissances et des ressources (le TX-0 en particulier, dont l’accès était limité). S. Lévy identifie six principes dans l’éthique <i lang="en" xml:lang="en">hacker</i> <a epub:type="noteref" href="#note_20" id="ref_20"> <sup>[20]</sup></a> : </p>
      <ol class="enumerate">
        <li>L’accès aux ordinateurs – ainsi que tout ce qui peut permettre de comprendre comment le monde fonctionne – doit être universel (pour tous) et sans restrictions. </li>
        <li>Toute information doit être libre. </li>
        <li>Se méfier de l’autorité – promouvoir la décentralisation. </li>
        <li>Les <i lang="en" xml:lang="en">hackers</i> doivent être jugés sur leurs activités (leurs hacks) et non suivant des critères « bidons » comme le diplôme, l’âge, l’origine ethnique ou le rang social. </li>
        <li>On peut créer l’art et le beau à l’aide d’un ordinateur. </li>
        <li>Les ordinateurs peuvent améliorer notre vie.</li>
      </ol>
      <p> Ces principes ont été analysés par le philosophe finlandais Pekka Himanen dans un essai intitulé <cite>L’éthique <i lang="en" xml:lang="en" class="droit">hacker</i> et l’esprit de l’ère de l’information</cite><a epub:type="noteref" href="#note_21" id="ref_21"> <sup>[21]</sup></a>. Pour Himanen, les principes <i lang="en" xml:lang="en">hacker</i> dépassent le seul cadre de l’informatique et formalisent une nouvelle éthique du travail dans une forme de relation passionnée qui s’oppose à la conception protestante à la base du capitalisme selon laquelle le travail est une finalité de l’existence, ainsi que l’exprimait Max Weber. Selon ce dernier en effet, </p>
      <blockquote>
        <p> [Le travail] est caractéristique de <em>l’éthique sociale</em> de la culture capitaliste et joue en un certain sens pour elle un rôle constitutif. C’est une obligation dont l’individu se sent et doit se sentir investi à l’égard du contenu de son activité <em>professionnelle</em>, peu importe en particulier qu’une saisie naïve l’identifie à l’exploitation pure d’une force de travail ou à celle de possessions et de biens (d’un <em>capital</em>). <a epub:type="noteref" href="#note_22" id="ref_22"> <sup>[22]</sup></a></p>
      </blockquote>
      <p> Selon Himanen, le <i lang="en" xml:lang="en">hacker</i> adopte d’abord une attitude et un engagement avant de considérer ses activités comme un métier dont le mobile principal n’est pas l’argent (bien que ce ne soit pas incompatible) mais la coopération directe, l’adhésion collective à un projet et l’indépendance par rapport à des instances (académiques, industrielles, etc.). </p>
      <p> Il est frappant de voir combien les <i lang="en" xml:lang="en">hackers</i> eux-mêmes ont toujours adhéré aux principes énoncés par S. Lévy. Tous se reconnaissent dans cet énumération, et citent bien souvent S. Lévy. </p>
      <p> Pekka Himanen la reprenant à son compte, c’est Linus Torvalds, concepteur du noyau de système d’exploitation Linux en 1989, qui préface l’ouvrage du philosophe (et il ne s’agit pas que d’une forme de solidarité nationale entre ces deux finlandais). Dans sa biographie même, co-écrite en 2001 avec le journaliste David Diamond <a epub:type="noteref" href="#note_23" id="ref_23"> <sup>[23]</sup></a>, Torvalds se décrit comme un <i lang="en" xml:lang="en">hacker</i>, nonobstant le fait qu’il considère que le partage des informations relève plus d’une attitude pragmatique visant à favoriser l’innovation et la créativité que d’un ensemble de valeurs morales auxquelles il serait censé adhérer <a epub:type="noteref" href="#note_24" id="ref_24"> <sup>[24]</sup></a>. Quant à Sam Williams, un autre journaliste, lors de l’écriture d’une première version de la biographie de Richard Stallman, il reprend les termes mêmes de Steven Lévy décrivant Stallman comme « le dernier des (vrais) <i lang="en" xml:lang="en">hackers</i> ». Puis, dans la réécriture de cette même biographie, avec votre serviteur comme témoin, Richard Stallman enrichit même l’annexe située en fin d’ouvrage traitant de l’histoire et de l’éthique <i lang="en" xml:lang="en">hacker</i> et reprenant le premier chapitre consacré de Steven Levy. Pour terminer cette énumération, nous pouvons aussi citer Eric S. Raymond, qui, non content de se reconnaître en <i lang="en" xml:lang="en">hacker</i>, écrit lui-même une brève histoire du <i lang="en" xml:lang="en">hacking </i>intitulée <cite lang="en" xml:lang="en">A Brief History of Hackerdom</cite><a epub:type="noteref" href="#note_25" id="ref_25"> <sup>[25]</sup></a>. </p>
      <p> La raison pour laquelle l’appartenance à la communauté <i lang="en" xml:lang="en">hacker</i> n’est pas qu’un sentiment mais une véritable revendication se rapporte aux deux premiers principes de Steven Levy : l’accessibilité à l’information de manière égalitaire, et le partage sans restriction de cette information. Ce sont là les principes fondamentaux de la coopération dans l’activité de programmation. Nous laisserons aux économistes la difficile question de savoir comment la coopération ouverte sans limiter la diffusion de l’information permet d’optimiser la dynamique de l’innovation et si elle est ou non plus efficace que les mécanismes classiques. À l’instar de Bob Bemer qui prônait pour les ingénieurs l’apprentissage de la programmation, nous pouvons dire que les principes <i lang="en" xml:lang="en">hacker</i> impliquent l’absence d’une quelconque séparation théorique entre le programmeur et l’utilisateur. Cela impliquait par exemple que dans le cas des ordinateurs à temps partagé, où il s’agissait de fournir un service (de temps de calcul) aux utilisateurs, ces derniers ne devaient en aucun cas voir leur accès au système limité par des droits d’accès : chacun devait pouvoir améliorer le système et partager ces améliorations <a epub:type="noteref" href="#note_26" id="ref_26"> <sup>[26]</sup></a>. Une transcription technique de ces principes revient à dire que le code d’un programme doit être lisible et modifiable par tous. La transcription juridique de ces « libertés logicielles » (ou de l’éthique <i lang="en" xml:lang="en">hacker</i>) que Richard Stallman a initiée au début des années 1980 s’appelle la licence libre, et les programmes, des programmes libres (ou <i lang="en" xml:lang="en">open source</i>), par contraste avec toutes sortes de programmes ne permettant pas l’application des libertés définies par les <i lang="en" xml:lang="en">hackers</i> <a epub:type="noteref" href="#note_27" id="ref_27"> <sup>[27]</sup></a>. </p>
      <p> Certes, nous venons de mentionner trois grandes « stars » qui, rétrospectivement se retrouvent pleinement dans une communauté à laquelle, bien qu’ayant des avis divergents (par exemple la différence d’approche entre l’<i lang="en" xml:lang="en">open source </i>et le <i lang="en" xml:lang="en">free software</i>), ils appartiennent et contribuent. L’effet rétrospectif doit ici être mesuré. Pour cela on peut se référer au fichier informatique <i lang="en" xml:lang="en" class="droit"><a href="http://jargon-file.org/archive/">Jargon File</a></i>, créé en 1975, qui constitue un glossaire du jargon utilisé dans les communautés <i lang="en" xml:lang="en">hacker</i> des deux laboratoires d’intelligence artificielle du <abbr lang="en" xml:lang="en">MIT</abbr> et de Stanford (<abbr lang="en" xml:lang="en">MIT AI</abbr> Lab. et Stanford AI Lab. – SAIL) ainsi que des autres communautés mobilisées autour des projets comme ARPANET ou MAC, des langages de programmation (comme LISP), ou même de firmes privées produisant des ordinateurs. En consultant les archives du Jargon File (mis à jour jusqu’à aujourd’hui), on peut remarquer que le terme <i lang="en" xml:lang="en">hacker</i> constitue une entrée intéressante, dès la première version du fichier. Elle n’a pas subi de grands changements jusqu’à la version 2.9.8 en janvier 1992 où apparaît seulement l’entrée <i lang="en" xml:lang="en">hacker ethic </i>qui fait explicitement référence, sans exclusivité toutefois, aux principes normatifs du projet GNU initié par Richard Stallman, en ces termes : « toute information doit être libre et tout contrôle privateur de celle-ci est mauvais (c’est la philosophie du Projet GNU) ». Dans la version de 1975, par contre, ce sont essentiellement les activités concrètes du <i lang="en" xml:lang="en">hacker</i> qui sont mentionnées : </p>
      <blockquote class="cadre_gris" lang="en" xml:lang="en">
        <p> HACKER — Originally, someone who makes furniture with an axe.</p>
        <ol>
          <li> n. A person who is good at programming quickly. Not everything a hacker produces is a hack. </li>
          <li> An expert at a particular program, example : "A SAIL hacker". </li>
          <li> A malicious or inquisitive meddler who tries to discover information by poking around. Hence "keyword hacker", "network hacker".</li>
        </ol>
      </blockquote>
      <p> Cette définition semble devoir se rapprocher davantage de l’interprétation de P. Himanen que de celle de S. Lévy. En effet, si nous partons du principe que le <i lang="en" xml:lang="en" class="droit">Jargon File</i> représente, à un moment donné de l’histoire, un témoignage de la représentation du <i lang="en" xml:lang="en">hacker</i> par lui-même, il est assez frappant de n’y trouver que peu de relation avec l’interprétation « philosophique » de Steven Lévy, surtout si l’on considère que l’entrée correspondant à l’éthique <i lang="en" xml:lang="en">hacker</i> apparaît plus de douze ans après la rédaction de son célèbre ouvrage. Ici, le talent, l’expertise et la persévérance des <i lang="en" xml:lang="en">hackers</i> semblent être des qualités davantage mentionnées lors d’un entretien d’embauche qu’en référence à un idéal de vie. Le <i lang="en" xml:lang="en">hacker</i> « fabrique des meubles avec une hache » (première phrase de l’entrée correspondante du <i lang="en" xml:lang="en" class="droit">Jargon File</i>), il est capable de s’adapter à des situations difficiles où les ressources sont limitées et son activité de programmeur s’en trouve d’autant plus novatrice. Ce sont bien là les atouts recherchés par la plupart des entreprises impliquées dans le développement de programmes informatiques, la fabrication d’ordinateurs ou la gestion de ressources de calcul en réseau, qui fleurissaient (ou étendaient leurs activités) durant les années 1960-1970. Les <i lang="en" xml:lang="en">hackers</i> inauguraient donc davantage qu’une nouvelle forme d’ingénierie informatique, mais bel et bien un mode nouveau de rapport au travail, une ingénierie artisanale avec de nouvelles normes auxquelles ils s’identifiaient, telles que mentionnées par P. Himanen. </p>
      <p> Il faut cependant souligner que ce dernier considère les <i lang="en" xml:lang="en">hackers</i> sous le spectre très large d’une histoire de plus de trente années de développement de logiciel libre. C’est en tout cas la manière dont il répond aux plus sceptiques. Deux économistes, J. Lerner et J. Tirole <a epub:type="noteref" href="#note_28" id="ref_28"> <sup>[28]</sup></a>, ont analysé en 2002 l’impact de la dynamique de projets <i lang="en" xml:lang="en">open source </i> sur le modèle économique des entreprises impliquées. S’inspirant des travaux de l’économiste B. Hermalin <a epub:type="noteref" href="#note_29" id="ref_29"> <sup>[29]</sup></a> sur le leadership, ils se réfèrent eux aussi à Max Weber et sa sociologie <a epub:type="noteref" href="#note_30" id="ref_30"> <sup>[30]</sup></a> mais pour montrer cette fois que les projets <i lang="en" xml:lang="en">open source </i>n’échappent pas au modèle classique de l’organisation sociale du travail : la confiance accordée au leader, l’harmonie entre les objectifs du leader et ceux des programmeurs au niveau individuel, l’absence de facteurs politiques ou commerciaux dans la reconnaissance du leadership (on pense bien évidemment au quatrième principe évoqué par S. Lévy, à propos du jugement), l’acceptation à priori de toute critique de fond visant à améliorer le projet, toutes ces qualités se retrouvant dans la théorie de Weber et qui ne semblent pas aussi révolutionnaires que Himanen le prétend. Ce dernier précise néanmoins que de nouvelles notions apparaissent bel et bien dans une hiérarchie davantage horizontale que verticale des projets de développement où les figures de supérieurs et d’exécutants ont tendance à s’effacer, notamment au profit de la possibilité d’une destitution du leader. Comme le dit l’économiste Pascal Jollivet en commentant Himanen : </p>
      <blockquote>
        <p> Pourtant, malgré les apparences, une différence fondamentale existe entre ces figures et celle du supérieur hiérarchique : <em>le statut d’autorité est ouvert à quiconque</em><a epub:type="noteref" href="#note_31" id="ref_31"> <sup>[31]</sup></a>. Ce qui est déterminant, c’est qu’une spécificité institutionnelle des projets en logiciel libre – nul ne peut se prévaloir d’avoir la propriété de biens logiciels produits dans le cadre de projet en licence libre – génère les conditions matérielles et sociales pour que cette autorité soit effectivement <em>ouverte </em>et destituable. <a epub:type="noteref" href="#note_32" id="ref_32"> <sup>[32]</sup></a></p>
      </blockquote>
      <p> L’appellation de <i lang="en" xml:lang="en">hacker</i> possède donc plusieurs acceptions et il est difficile de déterminer avec exactitude comment une communauté de <i lang="en" xml:lang="en">hackers</i> à pu naître et s’identifier en tant que telle, c’est-à-dire autour de principes tels que ceux énoncés par Steven Lévy, ou, plus généralement, autour d’une conception nouvelle du rapport au travail. Si, comme le montre le <i lang="en" xml:lang="en" class="droit">Jargon File</i>, la communauté <i lang="en" xml:lang="en">hacker</i> se définit elle même par un tel concept, les principes éthiques relèvent néanmoins d’une interprétation qui formalise rétrospectivement l’organisation du travail <i lang="en" xml:lang="en">hacker</i>, qui repose sur une division strictement horizontale du travail et une collaboration à tous les niveaux de la conception, de la programmation et de l’utilisation. </p>
      <p> En effet, à la différence des journalistes écrivant les épisodes biographiques qui marquèrent l’histoire du logiciel libre, tel Steven Lévy, David Diamond ou Sam Williams, les historiens se sont contentés de considérer comme tangible l’identification de cette petite population de programmeurs de génie, tant au <abbr lang="en" xml:lang="en">MIT</abbr> qu’à Stanford, sur laquelle repose une partie significative de l’innovation informatique des années 1970. Ainsi, Paul Ceruzzi, spécialiste de l’histoire des ordinateurs modernes, adopte une attitude différente lorsqu’il s’agit de situer, contextualiser, les pratiques <i lang="en" xml:lang="en">hackers</i>. Par exemple, à propos du rôle qu’a joué l’entreprise DEC (<i lang="en" xml:lang="en" class="droit">Digital Equipment Corporation</i>) en permettant aux programmeurs du <abbr lang="en" xml:lang="en">MIT</abbr> de modifier le <abbr>PDP1</abbr> aimablement donné par Kenneth Olsen (directeur de DEC), Ceruzzi mentionne : </p>
      <blockquote>
        <p> Olsen donna un autre <abbr>PDP-1</abbr> au <abbr lang="en" xml:lang="en">MIT</abbr> où il devint la référence légendaire dans la culture des <i lang="en" xml:lang="en">hackers</i> plus tard commémorée par le folklore populaire. <a epub:type="noteref" href="#note_33" id="ref_33"> <sup>[33]</sup></a></p>
      </blockquote>
      <p> Les termes et expressions comme « légendaire » et « folklore populaire » ne laissent aucun doute quant à la difficulté pour l’historien à prendre pour argent comptant l’interprétation de Steven Lévy pourtant accréditée par les <i lang="en" xml:lang="en">hackers</i> eux-mêmes, y compris ceux qui figurent parmi les acteurs principaux des décennies 1960 - 1970 - 1980. Leurs témoignages, bien que leurs recoupements permettent d’accréditer des faits, ne sont pas toujours les sources les plus fiables quant à l’interprétation de ceux-ci. Cependant, un consensus semble se dessiner dans l’acception du <i lang="en" xml:lang="en">hacker</i> comme un archétype d’agent vecteur de changement, à la fois par le partage de pratiques communes de travail, l’appartenance à une communauté ou à un projet social positif (même s’il n’est pas clairement défini) et par la place laissée à l’appropriation collective des connaissances nécessaires à l’innovation. Le <i lang="en" xml:lang="en">hacker</i> serait donc doublement vecteur de progrès : l’acteur du progrès technologique aux sources de la société de l’information d’aujourd’hui, mais aussi acteur de changement social, d’une nouvelle forme d’appropriation du changement technologique par le partage des connaissances et de l’immatériel (l’information en général, les logiciels, les pratiques d’ingénierie, etc.). </p>
      <p> Il est souvent tentant de penser le changement technologique sur une échelle linéaire, que par commodité l’on nomme <em>progrès</em>. Cette idée n’est cependant que l’impression d’une forme d’interdépendance des technologies au fil du temps. Ainsi, d’un point de vue trivial, il aura bien fallu inventer la roue et le moteur à explosion pour inventer la voiture. Pour être exact, il n’est en fait ici question que de la valeur <em>cumulative </em>des technologies <a epub:type="noteref" href="#note_34" id="ref_34"> <sup>[34]</sup></a> dans une société, ainsi que l’avait très justement analysé Lévy-Strauss (J. Schumpeter nous parle d’innovation <em>incrémentielle</em>). L’innovation s’analyse donc avec les notions de combinaison, mutation, transformation et appropriation, en opposition avec celle d’une prétendue continuité. Dans une société moderne, ces principes sont habituellement bien compris et toute entreprise confrontée à la nécessité concurrentielle dispose en elle les moyens d’encourager l’innovation, avec des méthodes plus ou moins efficaces d’alliance entre ingénierie, recherche et moyens humains. </p>
      <p> L’histoire d’Internet illustre particulièrement bien l’<em>accumulation </em>des technologies à l’œuvre dans la formation d’un réseau de réseaux (réseaux d’acteurs / réseautage et réseaux informatiques). L’arrivée des technologies de réseau (avant qu’Internet ne soit devenu générique) marqua sans doute la dernière étape structurelle de la naissance d’une communauté <i lang="en" xml:lang="en">hacker</i>, ou plus généralement de la culture Libre. </p>
    </section>

    <section epub:type="bodymatter subchapter">
      <h3 id="part1-2.4">2.4 Réseau</h3>
      <p> À la différence de projets clairement identifiés et stratégiquement planifiés, relevant parfois d’une volonté gouvernementale à l’image du projet Manhattan, Internet s’est développé de manière presque anarchique, avec un nombre d’utilisateurs restreints (les premiers utilisateurs de systèmes informatiques de communication à distance), des collaborateurs travaillant sur des aspects techniques différents, avec leurs calendriers propres de mise en œuvre, en somme, une accumulation de projets et de recherches théoriques, dont la convergence ne se comprend que d’un point de vue macroscopique et de manière rétrospective. Pour reprendre les termes de l’économiste Peter Meyer, il s’agirait donc d’une « invention collective », c’est-à-dire « un développement dont les améliorations et les découvertes expérimentales au sujet des processus de production ou les outils sont régulièrement partagés. » <a epub:type="noteref" href="#note_35" id="ref_35"> <sup>[35]</sup></a> </p>
      <p> Longtemps considérée comme l’incubateur principal d’un « projet Internet », la DARPA <a epub:type="noteref" href="#note_36" id="ref_36"> <sup>[36]</sup></a> fut dotée de moyens considérables aux frontières des sciences informatiques. Des chercheurs issus de plusieurs nationalités vinrent se joindre aux équipes dont l’une des plus importantes fut le projet Arpanet (<i lang="en" xml:lang="en" class="droit">Advanced Research Projects Agency Network</i>). De nombreux ouvrages <a epub:type="noteref" href="#note_37" id="ref_37"> <sup>[37]</sup></a> furent consacrés à cette histoire passionnante, mêlant la recherche académique, les institutions publiques et la planification d’État par les agences de moyens comme l’<abbr>IPTO</abbr> (<i lang="en" xml:lang="en" class="droit">Pentagon’s Information Processing Techniques Office</i>). Cette dernière, dédiée en premier lieu au développement de moyens pour la défense militaire, encouragea les interactions entre les institutions (entre l’ARPA et le monde académique) et le résultat fut la transition, effectuée sur une seule décennie, entre une informatique lourde et coûteuse (celle des énormes ordinateurs à traitement par lot, réservés à la recherche ou à quelques domaines bien spécifiques comme la banque ou les assurances) et une informatique réactive, avec une augmentation considérable de la puissance de calcul des ordinateurs, eux-mêmes dotés d’affichages graphiques, et assurant des systèmes de communication hautement sécurisés. </p>
      <p> À la lecture des principales publications entre 1958 et le début des années 1970, les deux principaux concepts qui permirent cette transition furent le temps partagé (<i lang="en" xml:lang="en">timesharing</i>) et la commutation de paquet. Pour l’exprimer simplement, le temps partagé permettait une gestion de l’accès au temps de calcul via un système d’interruption : le traitement de l’information lancé par un utilisateur pouvait s’interrompre pour attendre une autre série d’instructions tandis qu’un autre processus, lancé par un autre utilisateur, pouvait se dérouler de manière à optimiser le temps d’utilisation des capacités de la machine. Les impacts furent de trois types : le développement concurrentiel de machines possédant de grandes vitesses de traitement, la possibilité d’augmenter le nombre d’utilisateurs simultanés sur une même machine, et, corrélativement, l’abaissement du coût du temps de calcul. La commutation de paquet, quant à elle, s’oppose au concept de circuit commuté telle la communication téléphonique qui organise la circulation de l’information de point à point par un seul chemin élaboré au besoin (« Mademoiselle, passez-moi le 22 à Anières » <a epub:type="noteref" href="#note_38" id="ref_38"> <sup>[38]</sup></a>). </p>
      <p> Faire circuler l’information par paquets <a epub:type="noteref" href="#note_39" id="ref_39"> <sup>[39]</sup></a> permettait l’utilisation de chemins multiples, à l’échelle de tout le territoire et avec des vitesses record ce qui, d’un point de vue militaire a fini par représenter un intérêt stratégique d’importance, bien que les activités de l’ARPA n’étaient pas exclusivement dédiées à la recherche militaire <a epub:type="noteref" href="#note_40" id="ref_40"> <sup>[40]</sup></a>. Le projet ARPANET fut donc un projet qui a d’abord permis l’alliance entre plusieurs technologies sur un modèle expérimental et en réunissant, entre 1967 et 1969, seulement quatre universités-cobayes (<i lang="en" xml:lang="en" class="droit">Stanford Research Institute, University of California Los Angeles</i> et <i lang="en" xml:lang="en" class="droit">Santa Barbara, University of Utah</i>), ainsi que la firme <i lang="en" xml:lang="en" class="droit">Bolt, Beranek &amp; Newman (<abbr>BBn</abbr></i>) qui avait répondu à l’appel d’offres pour la maintenance du réseau et l’élaboration des routeurs (<abbr>IMP</abbr> – <i lang="en" xml:lang="en">Interface Message Processor</i>) sur la base des ordinateurs de la gamme <abbr>PDP</abbr> fournis par la firme Honeywell. À cela nous devons ajouter la rapide intégration du projet Multics et de ses acteurs au <abbr lang="en" xml:lang="en">MIT</abbr>. </p>
      <p> L’idée <em>Internet </em>n’intervint qu’assez tard, d’abord sur l’idée de l’<i lang="en" xml:lang="en">internetting</i>, c’est-à-dire la possibilité d’utiliser les petits réseaux existants et hétérogènes en permettant leur interconnexion, d’autant plus facilitée par la possibilité de rendre les paquets d’information indépendants (datagrammes), de manière à favoriser leur passage de réseaux en réseaux. Pour cela, il a fallu développer collectivement tout un ensemble de protocoles de communications qui débouchèrent sur les protocoles <abbr>TCP/IP</abbr>. Ce n’est qu’en octobre 1972, lors de la première <i lang="en" xml:lang="en" class="droit">International Conference on Computer Communication</i> qu’eut lieu une démonstration publique des principes de l’<i lang="en" xml:lang="en">internetting</i><a epub:type="noteref" href="#note_41" id="ref_41"> <sup>[41]</sup></a>. Ce fut ensuite l’<i lang="en" xml:lang="en" class="droit">Amendement Mansfield</i> qui, en 1973, circonscrit les recherches de l’ARPA au domaine relevant uniquement de la Défense (ARPA devint DARPA). La controverse qui s’ensuivit fut essentiellement alimentée par la <i lang="en" xml:lang="en" class="droit">National Science Foundation</i> car cette restriction n’était pas seulement institutionnelle mais privait l’ARPA des fonds conséquents apportés par celle-ci et de toutes les perspectives en termes de marchés que laissaient présager les avancées menées depuis plus de dix ans. </p>
      <p> Pourtant, comme le note <i lang="en" xml:lang="en" class="droit">Shane Greenstein</i> <a epub:type="noteref" href="#note_42" id="ref_42"> <sup>[42]</sup></a>, l’<i lang="en" xml:lang="en" class="droit">Amendement Mansfield</i> ne mit pas un terme aux échanges entre les acteurs provenant d’institutions différentes. Il y a deux raisons à cela, qui nous ramènent aux années 1960. La première est que ARPANET se devait de composer un réseau permettant l’émergence de protocoles communs, de manière à assurer la viabilité des échanges d’information non seulement entre machines mais aussi entre différents réseaux et, pour cela, avait besoin d’accéder à des réseaux autres que militaires. La seconde raison focalise sur les rôles individuels. Comme l’explique très bien Alexandre Serres <a epub:type="noteref" href="#note_43" id="ref_43"> <sup>[43]</sup></a>, l’ARPA bénéficiait d’une assez large autonomie vis-à-vis de son agence de moyen, l’<abbr>IPTO</abbr>, grâce aux relations interpersonnelles entre acteurs des deux instances. D’un autre côté, la proximité entre l’ARPA et la firme <abbr>BBN</abbr> doit être soulignée. Cette firme, créée par deux professeurs du <abbr lang="en" xml:lang="en">MIT</abbr> (Leo Beranek et Richard Bolt, auxquels se rajouta un de leurs étudiants, Robert Newman) avait par ailleurs des relations privilégiées avec le <abbr lang="en" xml:lang="en">MIT</abbr> où les chercheurs, toujours en relation avec leurs anciens collègues, travaillaient sur différents projets de <abbr>BBN</abbr>, qu’il s’agisse de la mise en place de l’ARPANET à la conception de programmes adaptés aux ordinateurs <abbr>PDP</abbr> de chez <i lang="en" xml:lang="en" class="droit">Digital Equipment Corporation</i>, elle aussi partenaire de <abbr>BBN</abbr>. </p>
      <p> En somme, l’émergence d’ARPANET n’est pas seulement la création d’un réseau informatique, c’est aussi, par l’imbrication entre l’industrie, la recherche et les projets militaires, un réseau relationnel d’affinités <a epub:type="noteref" href="#note_44" id="ref_44"> <sup>[44]</sup></a> : non seulement un nombre important de chercheurs et d’étudiants devinrent familiers avec les principes développés par l’ARPA, mais c’est aussi pour l’ARPA la reconnaissance qu’une grande partie de sa force de travail, d’inspiration et de conception était externalisée sur les acteurs-utilisateurs, tous capables d’apporter leur lot d’améliorations et de mise en œuvre. En somme, ce que montre l’exemple de l’ARPA, c’est qu’une dynamique d’échanges et d’appropriations de concepts, d’expertise et de connaissances a été aménagée par les agences de moyens, <abbr>IPTO</abbr> et <abbr>NSF</abbr>, de manière à institutionnaliser les pratiques et identifier, sur une base de confiance mutuelle, les apports pertinents à un projet encore flou, qui devint plus tard Internet. </p>
      <p> C’est tout à fait paradoxalement que cette institutionnalisation et ces relations interpersonnelles de convergences d’intérêts, donna le jour à d’autres communautés de pratiques qui entraient en conflit avec l’ordre établi bien qu’elles contribuèrent grandement aux structures informatiques en réseau. </p>
      <p> Comme on peut le montrer en étudiant justement le cas des contributions au noyau Linux <a epub:type="noteref" href="#note_45" id="ref_45"> <sup>[45]</sup></a>, dans un processus d’innovation, les individus qui créent de nouvelles connaissances produisent en même temps un apprentissage organisationnel, qui permet de cristalliser cette connaissance au niveau collectif, en formant une communauté épistémique. Cette cristallisation s’effectue à travers la circulation de « bonnes pratiques », c’est-à-dire celles qui favorisent la circulation des connaissances. L’innovation dépend donc essentiellement d’un cadre social auto-incitatif dont la première motivation est la mise en commun des connaissances. </p>
      <p> Cette conclusion est à mettre en perspective avec ce qui se passa en 1969, lors de la jonction entre la phase de maturité d’un système d’exploitation à temps partagé (<abbr>CTSS</abbr> – <i lang="en" xml:lang="en" class="droit">Compatible Time-Sharing System / Multics</i>) d’où découlait la notion de <i lang="en" xml:lang="en">computer utility</i>, c’est-à-dire l’avènement d’une économie de service terminal / ordinateur central, et l’expérimentation « universitaro-industrielle » de transfert de l’information en réseau (la naissance d’ARPANET, qui reliait alors plusieurs campus) rendue possible grâce aux machines de <abbr>BBN</abbr> et de DEC. Les retombées utilitaires de ces projets laissaient présager un marché intéressant comme, pour prendre des exemples autres que militaires, équiper les banques de systèmes de gestion, permettre aux industries de mutualiser des gros calculateurs, voire de permettre à tous les habitants d’une ville d’accéder, via autant de terminaux par foyer, à des ressources système et même des contenus informatifs <a epub:type="noteref" href="#note_46" id="ref_46"> <sup>[46]</sup></a>… Or, ce qui caractérisait à cette époque le système <abbr>CTSS</abbr> au <abbr lang="en" xml:lang="en">MIT</abbr> était la volonté des administrateurs à rendre étanches les sessions d’utilisation de l’ordinateur central, tout en instaurant une hiérarchie de droits d’utilisation, reflets structurels de la hiérarchie institutionnelle entre chercheurs, professeurs, directeurs, ingénieurs - programmeurs. Ce type de rigidité tendait à se mettre en place dans toutes les universités où s’expérimentaient les prémisses d’Internet, et allait à l’encontre des <i lang="en" xml:lang="en">bonnes pratiques </i>mises en œuvre dans la communauté <i lang="en" xml:lang="en">hacker</i> qui dès lors se reconnut en tant que communauté partageant un ensemble de valeurs différentes (les principes <i lang="en" xml:lang="en">hacker</i> de mises en commun des connaissances et de l’information sans contraintes) et qui s’exprimaient en réaction à l’organisation institutionnelle, par l’intermédiaire du réseau lui-même. </p>
      <p> Entre 1968 et 1969, le témoignage le plus saisissant fut la création, par les <i lang="en" xml:lang="en">hackers</i> du <abbr lang="en" xml:lang="en">MIT</abbr>, du système <abbr>ITS</abbr> (<i lang="en" xml:lang="en" class="droit">Incompatible Timesharing System</i>), nommé en réaction au système <abbr>CTSS</abbr>. Les concepteurs de l’<abbr>ITS</abbr> furent <i lang="en" xml:lang="en" class="droit">Richard Greenblatt</i>, <i lang="en" xml:lang="en" class="droit">Tom Knight</i>, <i lang="en" xml:lang="en" class="droit">Jack Holloway</i> et <i lang="en" xml:lang="en" class="droit">Stuart Nelson</i>. La principale caractéristique de l’<abbr>ITS</abbr> était la possibilité de transformer le système lui-même à chaque instant : connecté en permanence au réseau, l’<abbr>ITS</abbr> permettait à un utilisateur de travailler sur tous les fichiers (y compris les fichiers système) depuis n’importe quel terminal en toute transparence. Ce n’était pas anodin, puisque cette pratique donna naissance à deux autres innovations dont profitèrent les autres projets et bien des systèmes aujourd’hui : l’exploitation asynchrone des processus (plus besoin d’attendre la fin d’un processus pour en entamer un autre) et l’utilisation du PC-Lusering permettant de gérer stratégiquement les files d’attente en organisant une surveillance des processus en cours et qui entrent en concurrence pour l’acquisition de temps de calcul <a epub:type="noteref" href="#note_47" id="ref_47"> <sup>[47]</sup></a>. En somme : une optimisation des ressources du système et du temps de calcul disponible, pour un système informatif permettant de gérer les tâches de chacun. </p>
      <p> Il faut lire entre les lignes de l’introduction du manuel de l’<a href="ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-161A.pdf"><abbr>ITS</abbr></a>, où l’on apprend que ce système a été élaboré « sur mesure » (<i lang="en" xml:lang="en">tailored</i>) pour le Projet MAC (le groupe du <abbr lang="en" xml:lang="en">MIT</abbr> travaillant en intelligence artificielle). Il a été conçu comme « une tentative de fournir des avantages potentiels d’un système à temps partagé », ce qui sous-entendait que <abbr>CTSS</abbr> ne le faisait pas. On peut énumérer par exemple, l’accès de tous les utilisateurs sans ordre hiérarchique (ni mot de passe) ou la possibilité pour tous de disposer d’une commande d’interruption du système. Bien entendu l’<abbr>ITS</abbr> ne s’adressait qu’à un « nombre limité d’utilisateurs » qui avaient « besoin d’un haut niveau de services sophistiqués ». En d’autres termes, l’<abbr>ITS</abbr> démontrait aussi que la créativité en matière de programmation ne nécessitait pas seulement l’accès de tous à des ressources matérielles, aussi performantes soient-elles grâce aux remontées entre utilisateurs (les universitaires) et les fabricants. L’un des facteurs de réussite était aussi dans le partage sans contrainte de l’information et des droits d’utilisation, ce qui émulait la coopération entre programmeurs et non l’esprit de compétitivité. Si nous acceptons cet anachronisme, nous pouvons dire que le système <abbr>ITS</abbr> est le premier système d’exploitation « libre », dans le sens où il traduit à la lettre les principes <i lang="en" xml:lang="en">hacker</i>. </p>
    </section>

    <section epub:type="bodymatter subchapter">
      <h3 id="part1-2.5">2.5 Une contre-culture ?</h3>
      <p> Si les <i lang="en" xml:lang="en" class="droit">hackers</i> sont bien ces <em>ingénieurs hétérogènes </em>dont nous parlait B. Pfaffenberger, porteurs de valeurs et de représentations, il est toujours étonnant d’apprendre sous la plume de nombreux auteurs du monde journalistique qu’ils sont considérés comme les acteurs d’un mouvement de contre-culture. Si l’on s’en tient à la définition de ce néologisme (<i lang="en" xml:lang="en">counter-culture</i>) créé par le sociologue-historien Théodore Roszack <a epub:type="noteref" href="#note_48" id="ref_48"> <sup>[48]</sup></a> analysant les mouvements de jeunesse des années 1960, la contre-culture est un mouvement de revendication contestataire à l’encontre des régimes technocratique des sociétés. De ce point de vue, les <i lang="en" xml:lang="en">hackers</i> des années 1960 sont bien loin d’être « contestataires » : ils passent le plus clair de leur temps à chercher les moyens de coopération les plus efficaces et, en cela, reproduisent des modèles de coopération déjà anciens hérités de l’ingénierie d’après-guerre. En revanche, ces modèles, ces « communautés de pratiques » <a epub:type="noteref" href="#note_49" id="ref_49"> <sup>[49]</sup></a>, impliquent un ensemble de comportements incompatibles avec l’appropriation d’une technologie telle qu’elle permet au « propriétaire » d’utiliser un pouvoir sur les utilisateurs, en particulier lorsque ce pouvoir s’exerce sur les droits d’utilisation et instaure une hiérarchie là où la coopération se fait sur un mode égalitaire. Telle fut l’illustration de l’<abbr>ITS</abbr>. </p>
      <p> L’émergence d’Internet fut à postériori considérée comme une invention de chercheurs pour des chercheurs, c’est-à-dire une invention qui permettait de passer d’une informatique de calcul à une informatique permettant la circulation de l’information dans un cadre inédit et prometteur. Ce faisant, comme on le sait, Internet a multiplié les lieux de pouvoir (qu’ils soient démocratiques, comme la liberté d’opinion et d’information, ou moins démocratiques comme la surveillance des informations personnelles), et ce n’est que très récemment que la contre-culture <i lang="en" xml:lang="en">hacker</i> peut éventuellement se reconnaître comme telle. </p>
      <p> Le <i lang="en" xml:lang="en">hacking</i> est un humanisme : il est passé d’une simple recherche d’efficacité dans l’organisation du travail à une éthique qui ne sépare pas utilisateur et concepteur. Et dans cette quête de l’optimisation des capacités cognitives et des savoirs-faire, ainsi que de la diffusion des connaissances et des créations, il est un modèle de bon usage des facultés humaines. Dans la mesure où, pour reprendre l’idée de Bob Bemer, il faudrait que tout utilisateur soit programmeur, le hacking constitue sans doute l’une des clés des nouvelles formes d’innovations collectives de ce siècle, qu’il s’agisse de technologie, de culture ou de politique. </p>
    </section>

    <aside epub:type="footnotes" class="epub-footnotes">
      <ul>
        <li><a epub:type="footnote" href="#ref_1" id="note_1">1.</a> <span class="auteur">Steele Jr.</span>, Guy L. et <span class="auteur">Richard</span> P. Gabriel « <i lang="en" xml:lang="en">The Evolution of Lisp</i> » dans <cite lang="en" xml:lang="en">The second <abbr>ACM</abbr> SIGPLAN conference on History of programming languages</cite>  <i lang="en" xml:lang="en">New York</i>, <abbr lang="en" xml:lang="en">NY</abbr>, <abbr>USA</abbr> : <abbr><a href="http://doi.acm.org/10.1145/154766.155373">ACM</a></abbr>, 1993, HOPL-<abbr class="chiffre-romain" title="deux">ii</abbr>.</li>
        <li><a epub:type="footnote" href="#ref_2" id="note_2">2.</a> <span class="auteur">Bemer</span>, Robert W. « <i lang="en" xml:lang="en">What the Engineer Should Know Computer Programming</i> » dans <cite lang="en" xml:lang="en">Automatic Control Magazine 2</cite>, Feb./Mar. 1957 (document aimablement fourni par le <i lang="en" xml:lang="en" class="droit">>Charles Babbage Institute</i>).</li>
        <li><a epub:type="footnote" href="#ref_3" id="note_3">3.</a> <span class="auteur">McCarthy</span>, John « <i lang="en" xml:lang="en" class="droit">History of LISP</i>. <cite lang="en" xml:lang="en"><abbr>ACM</abbr>-SIGPLAN Notices</cite>, 13 (1978), 217-233.</li>
        <li><a epub:type="footnote" href="#ref_4" id="note_4">4.</a> <span class="auteur">Ceruzzi</span>, Paul E. <cite lang="en" xml:lang="en">A History of Modern Computing</cite>. Cambridge, Mass. : <abbr lang="en" xml:lang="en">MIT</abbr> Press, 1998 p. 4</li>
        <li><a epub:type="footnote" href="#ref_5" id="note_5">5.</a> <span class="auteur">Pfaffenberger</span>, Bryan « <i lang="en" xml:lang="en" class="droit">The Social Meaning of the Personal Computer: or, Why the Personal Computer Revolution Was not a Revolution</i> » dans <cite lang="en" xml:lang="en">Anthropological Quarterly</cite>, 61.1 1988 p39-47.</li>
        <li><a epub:type="footnote" href="#ref_6" id="note_6">6.</a> <span class="auteur">Abbate</span>, Janet, « L’histoire de l’Internet au prisme des <abbr>STS</abbr> », dans <cite><a href="http://www.cairn.info/revue-le-temps-des-medias-2012-1-p-170.htm">Le Temps des médias</a></cite>, 18.1 (2012), p.170.</li>
        <li><a epub:type="footnote" href="#ref_7" id="note_7">7.</a> <span class="auteur">Rich</span>, Ben R. et Leo <span class="auteur">Janos</span>, <cite lang="en" xml:lang="en">Skunk Works: A Personal Memoir of My Years of Lockheed</cite> <i lang="en" xml:lang="en" class="droit">1st Pbk. Ed, Back Bay Books</i>, février 1996.</li>
        <li><a epub:type="footnote" href="#ref_8" id="note_8">8.</a> <i lang="la" xml:lang="la">ibid.</i>, p6. B. Rich rapporte sur ce point : <q>Nous pensions que le <abbr>KGB</abbr> connaissait nos principaux numéros de téléphone, et des dispositifs d’enregistrement informatisés devaient probablement s’allumer à bord de ces chalutiers [au large des côtes californiennes] lorsque ces téléphones sonnaient. Les services secrets américains avaient régulièrement intercepté des références aux <i lang="en" xml:lang="en" class="droit">shunk works</i> au travers des communications satellites soviétiques, probablement parce qu’il n’y avait pas de traduction en russe pour ce surnom si particulier. Notre nom officiel était : <i lang="en" xml:lang="en" class="droit">Lockheed’s Advanced Development Projects</i>.</q></li>
        <li><a epub:type="footnote" href="#ref_9" id="note_9">9.</a> <i lang="en" xml:lang="en" class="droit">Shane Greenstein</i>, spécialiste en économie de l’innovation en informatique, montre comment les <i lang="en" xml:lang="en" class="droit">shunk works</i> (et les <i lang="en" xml:lang="en" class="droit">wild ducks</i>, que nous verrons plus loin) sont deux modèles pertinents pour analyser les mécanismes d’innovation au sein de la DARPA dans les projets qui donnèrent naissance à Internet. Voir <span class="auteur">Greenstein</span>, Shane <i lang="en" xml:lang="en" class="droit">Nurturing the Accumulation of Innovations: Lessons from the Internet</i> dans <cite lang="en" xml:lang="en"> <a href="http://www.nber.org/books/hend09-1">Accelerating Energy Innovation: Insights from Multiple Sectors</a></cite> Univ. of Chicago Press édition. Chicago : Henderson, R. and Newell, G., 2011, <i lang="en" xml:lang="en" class="droit">National Bureau of Economic Research Conference Report</i>.</li>
        <li><a epub:type="footnote" href="#ref_10" id="note_10">10.</a> <span class="auteur">Levy</span>, Steven <cite lang="en" xml:lang="en"> Hackers. Heroes of the Computer Revolution</cite> <i lang="en" xml:lang="en" class="droit">New York : Dell Publishing</i>, 1994.</li>
        <li><a epub:type="footnote" href="#ref_11" id="note_11">11.</a> H. Hollerith, professeur de mécanographie au <abbr lang="en" xml:lang="en">MIT</abbr> à partir de 1882, fonda <i lang="en" xml:lang="en" class="droit">Tabulating Machine Co.</i> en 1896, suite à son invention dont l’histoire technique est fort intéressante puisqu’il s’agit de ce qu’on appelle un transfert de technologie (entre le tissage industriel et ce qui deviendra l’informatique) qui fonda les bases de la mécanographie : l’utilisation du modèle de métier à tisser Jacquard, qui utilisait des rubans de cartonnages perforés, afin de mécaniser le traitement des données statistiques (notamment le pointage du recensement de population) en utilisant le principe des cartes perforées.</li>
        <li><a epub:type="footnote" href="#ref_12" id="note_12">12.</a> Voir l’ouvrage édité à l’occasion des 100 ans d’<abbr>IBM</abbr>, <span class="auteur">Maney</span>, Kevin, Steve <span class="auteur">Hamm</span> et Jeffrey <span class="auteur">O’Brien</span> <cite lang="en" xml:lang="en">Making the World Work Better: The Ideas That Shaped a Century and a Company</cite> 1<sup>ère</sup> édition. <abbr>IBM</abbr> Press, juin 2011. Voir aussi le <a href="http://www.ibm.com/ibm100">site internet</a> consacré au centenaire de la firme.</li>
        <li><a epub:type="footnote" href="#ref_13" id="note_13">13.</a> On pourra se référer à l’excellent article de Simon Donig sur la concurrence que se livrèrent les deux entreprises américaines <abbr>IBMi</abbr> et <abbr>CDC</abbr> <i lang="en" xml:lang="en" class="droit">(Control Data Corporation)</i> sur le marché de l’Allemagne de l’Est dans les années 1960. Cet article brise les idées reçues à propos de l’appropriation des technologies du bloc Ouest et montre à quel point la circulation des techniques suppose aussi une circulation des idées, nonobstant les questions d’espionnage industriel, inévitables dans cette histoire. <span class="auteur">Donig</span>, Simon « <i lang="en" xml:lang="en" class="droit">Appropriating American Technology in the 1960s: Cold War Politics and the <abbr>GDR</abbr> Computer Industry</i> ». <cite lang="en" xml:lang="en"><abbr>IEEE</abbr> Annals of the History of Computing</cite>, 32.2 2010.</li>
        <li><a epub:type="footnote" href="#ref_14" id="note_14">14.</a> <span class="auteur">Watson</span>, Thomas J. <cite lang="en" xml:lang="en">A Business and Its Beliefs: The Ideas That Helped Build <abbr>IBM</abbr></cite>. 1<sup>ère</sup> édition. McGraw-Hill, avril 2003.</li>
        <li><a epub:type="footnote" href="#ref_15" id="note_15">15.</a> <i lang="la" xml:lang="la">ibid.</i>, p. 14.</li>
        <li><a epub:type="footnote" href="#ref_16" id="note_16">16.</a> <span class="auteur">Tomash</span>, Erwin et ARNOLD A. <span class="auteur">Cohen</span> « <i lang="en" xml:lang="en" class="droit">The Birth of an ERA: Engineering Associates, Inc. 1946-1955</i> ». dans <cite lang="en" xml:lang="en">Annals of the History of Computing</cite>, 1 juin 1979, Nr. 2.</li>
        <li><a epub:type="footnote" href="#ref_17" id="note_17">17.</a> <span class="auteur">Astrahan</span>, Morton M. et John F. <span class="auteur">Jacobs</span> « <i lang="en" xml:lang="en" class="droit">History of the Design of the SAGE Computer - the AN/FSQ-7</i> », dans : <cite lang="en" xml:lang="en"><abbr>IEEE</abbr> Annals of the History of Computing, 5.4</cite> » (1983) p.343-344.</li>
        <li><a epub:type="footnote" href="#ref_18" id="note_18">18.</a> <span class="auteur">Pugh</span>, Emerson <cite lang="en" xml:lang="en">Memories that Shaped an Industry: Decisions Leading to <abbr>IBM</abbr> System/360</cite>, Cambridge, <abbr>MA</abbr> : <abbr>MIT</abbr> Press, 1984.</li>
        <li><a epub:type="footnote" href="#ref_19" id="note_19">19.</a> Ces interviews relèvent de toute une tradition de l’histoire orale dans le domaine de l’histoire informatique. Pour s’en convaincre, il suffit de constater l’immense travail du <i lang="en" xml:lang="en" class="droit">Charles Babbage Institute</i> dans la collecte de transcriptions d’interviews d’acteurs de l’histoire informatique et des ordinateurs, depuis la fin des années 1980. Beaucoup d’historiens, dont on peut lire les travaux dans les <cite lang="en" xml:lang="en">Annals of the History of Computing</cite>, ont travaillé sur ces archives inestimables.</li>
        <li><a epub:type="footnote" href="#ref_20" id="note_20">20.</a> <span class="auteur">Levy</span>, <i lang="la" xml:lang="la">op. cit. p. 28 sq.</i></li>
        <li><a epub:type="footnote" href="#ref_21" id="note_21">21.</a> <span class="auteur">Himanen</span>, Pekka <cite>L’Ethique Hacker et l’Esprit de l’ère de l’information</cite>, Paris : Exils, Éditions de l’Attribut, 2001.</li>
        <li><a epub:type="footnote" href="#ref_22" id="note_22">22.</a>  <span class="auteur">Weber</span>, Max <cite>L’Ethique protestante et l’Esprit du capitalisme</cite>, Paris : Flammarion, 1999 p. 94 (cité par Himanen, <i lang="la" xml:lang="la">op. cit.</i> p. 27).</li>
        <li><a epub:type="footnote" href="#ref_23" id="note_23">23.</a> <span class="auteur">Torvald</span>, Linus et David <span class="auteur">Diamond</span> <cite>Il était une fois Linux : L’extraordinaire histoire d’une révolution accidentelle</cite>, Paris : Osman Eyrolles Multimédia, 2001.</li>
        <li><a epub:type="footnote" href="#ref_24" id="note_24">24.</a> Cette position le rendit célèbre à maintes reprises, notamment parce que Torvalds la tient comme contradictoire, par interviews interposés, à la conception de Richard Stallman, pour lequel les principes des libertés logicielles ont une valeur morale, en plus de normer les comportements. Plus qu’une simple divergence de point de vue, les propos sont souvent véhéments, ainsi que le montre un interview de Torvalds en mai 2011, pour le site <a href="http://linuxfr.org/news/linus-torvalds-l'interview-anniversaire-des-20-ans-du-noyau">LinuxFr</a>, à l’occasion de l’anniversaire des vingt ans du noyau Linux : « […] Je méprise complètement les gens qui tentent de pousser la <abbr>GPL</abbr> [<abbr>NdR</abbr> : la Licence Publique Générale, initiée par R. M. Stallman] comme étant de type <em>éthique</em>. Je pense que c’est de la pure connerie. Pourquoi ? Parce que l’éthique, pour moi, c’est quelque chose de privé. Chaque fois que vous l’utilisez dans un argument pour dire pourquoi quelqu’un d’autre devrait faire un truc, alors vous n’adoptez plus une attitude éthique. Vous devenez juste une tête de con moralisatrice ».</li>
        <li><a epub:type="footnote" href="#ref_25" id="note_25">25.</a> <span class="auteur">Raymond</span>, Eric S. et al. « <i lang="en" xml:lang="en" class="droit">A Brief History of Hackerdom</i> », dans : <cite lang="en" xml:lang="en">Open Sources. Voices from the Open Source Revolution</cite>, Cambridge, <abbr>MA</abbr> : O’Reilly, 1999.</li>
        <li><a epub:type="footnote" href="#ref_26" id="note_26">26.</a> Témoignage de l’esprit potache des <i lang="en" xml:lang="en" class="droit">hackers</i>, un petit jeu est entré dans le folklore, consistant à appliquer cette éthique de l’accès au machine en fracturant (avec élégance) les portes des bureaux des professeurs qui empêchaient l’accès à leur terminaux « personnels » reliés au réseau. Voir sur ce point <span class="auteur">Williams</span>, Sam, Richard <span class="auteur">Sitallman</span> et Christophe <span class="auteur">Masutti</span> <cite>Richard Stallman et la révolution du logiciel libre. Une biographie autorisée</cite>. Paris: Eyrolles, 2010 pp. 64-65.</li>
        <li><a epub:type="footnote" href="#ref_27" id="note_27">27.</a> Après le travail de Richard Stallman et Eben Moglen au début des années 1980 pour définir, dans le cadre du projet GNU, une licence de copyright logiciel respectueuse des droits et libertés des utilisateurs, les quatre libertés logicielles à la base de la Licence Publique Générale (<abbr>GPL</abbr>) et formulées par la <i lang="en" xml:lang="en" class="droit">Free Software Foundation</i> sont : la liberté d’exécuter le programme quel qu’en soit l’usage, la liberté d’étudier le (code du) programme et le modifier pour ses besoins, la liberté de distribuer des copies du programme (de manière commerciale ou non), la liberté d’améliorer le programme et distribuer ces améliorations pour en faire profiter la communauté.</li>
        <li><a epub:type="footnote" href="#ref_28" id="note_28">28.</a> <span class="auteur">Lerner</span>, Josh et Jean <span class="auteur">Tirole</span>, « <i lang="en" xml:lang="en" class="droit">Some Simple Economics of Open Source</i> dans : <cite lang="en" xml:lang="en">Journal of Industrial Economics 52</cite> (2002), mentionné par P. Jollivet (voir <i>infra</i>).</li>
        <li><a epub:type="footnote" href="#ref_29" id="note_29">29.</a> <span class="auteur">Hermalin</span>, Benjamin E. « <i lang="en" xml:lang="en" class="droit">Towards an Economic Theory of Leadership: Leading by Example</i> », dans : <cite lang="en" xml:lang="en">American Economic Review 88</cite> (1998), p. 1188-1206.</li>
        <li><a epub:type="footnote" href="#ref_30" id="note_30">30.</a> <span class="auteur">Weber</span>, Max <cite>Économie et Société</cite>, Paris : Plon, 1971.</li>
        <li><a epub:type="footnote" href="#ref_31" id="note_31">31.</a> <span class="auteur">Himanen</span>, <i>op. cit.</i> p.80.</li>
        <li><a epub:type="footnote" href="#ref_32" id="note_32">32.</a> <span class="auteur">Jollivet</span>, Pascal « L’éthique <i lang="en" xml:lang="en" class="droit">hacker</i> et l’esprit de l’ère de l’information de Pekka Himaneni, dans : <cite>Multitudes, 1.8</cite> (2002) p. 165.</li>
        <li><a epub:type="footnote" href="#ref_33" id="note_33">33.</a> <span class="auteur">Ceruzzi</span>, <i>op. cit.</i> p. 128.</li>
        <li><a epub:type="footnote" href="#ref_34" id="note_34">34.</a> <span class="auteur">Jacomy</span>, Bruno <cite>L’Âge du plip : Chroniques de l’innovation technique</cite>, Paris : Seuil, 2002.</li>
        <li><a epub:type="footnote" href="#ref_35" id="note_35">35.</a> <span class="auteur">Meyer</span>, Philip <cite lang="en" xml:lang="en">Precision Journalism. A Reporter’s Introduction to Social Science Method</cite>, Indianapolis : Indiana University Press, 1973.</li>
        <li><a epub:type="footnote" href="#ref_36" id="note_36">36.</a> <i lang="en" xml:lang="en" class="droit">Defense Advanced Research Projects Agency</i>. Agence créée en 1957, le D fut ajouté vers 1972.</li>
        <li><a epub:type="footnote" href="#ref_37" id="note_37">37.</a> Voir en particulier <span class="auteur">Norberg</span>, Arthur L. et Judy E. <span class="auteur">O’Neill</span> <cite lang="en" xml:lang="en">Transforming Computer Technology: Information Processing for the Pentagon, 1962-1986</cite>, Baltimore : <i lang="en" xml:lang="en" class="droit">The Johns Hopkins University Press</i>, février 2000.</li>
        <li><a epub:type="footnote" href="#ref_38" id="note_38">38.</a> Référence au sketch célèbre de Fernand Raynaud (1926-1973) à propos des relations difficiles entre un client et une préposée des Postes et Télécommunications.</li>
        <li><a epub:type="footnote" href="#ref_39" id="note_39">39.</a> Il faut encore que ces paquets puissent obéir à des protocoles de communication.</li>
        <li><a epub:type="footnote" href="#ref_40" id="note_40">40.</a> <span class="auteur">Roland</span>, Alex et Philipp <span class="auteur">Shiman</span> <cite lang="en" xml:lang="en">Strategic Computing DARPA and the Quest for Machine Intelligence 1983-1993</cite>, Cambridge, <abbr>MA</abbr> : <abbr lang="en" xml:lang="en">MIT</abbr> Press, 2002.</li>
        <li><a epub:type="footnote" href="#ref_41" id="note_41">41.</a> <span class="auteur">Cerf</span>, Vinton G. <i lang="en" xml:lang="en"><a href="http://www.cs.washington.edu/homes/lazowska/cra/networks.html">Computer Networking: Global Infrastructure for the 21st Century</a></i> dans <cite lang="en" xml:lang="en">Computing Research: A National Investment for Leadership in the 21st Century</cite>, <i lang="en" xml:lang="en">Washington, <abbr>DC: CRA</abbr></i>, 1995.</li>
        <li><a epub:type="footnote" href="#ref_42" id="note_42">42.</a> <span class="auteur">Greestein</span>, Shane <i lang="en" xml:lang="en">Nurturing the Accumulation of Innovations: Lessons from the Internet</i> dans <cite lang="en" xml:lang="en"><a href="http://www.nber.org/books/hend09-1">Accelerating Energy Innovation: Insights from Multiple Sectors. Univ. of ChicagoPress edition</a></cite> Chicago: Henderson, R. and Newell, G., 2011, National Bureau of Economic Research Conference Report.</li>
        <li><a epub:type="footnote" href="#ref_43" id="note_43">43.</a> <span class="auteur">Serres</span>, Alexandre <cite>Aux sources d’internet : l’émergence d’ARPANET</cite>. Thèse en Sciences de l’information et de la communication Université de Rennes, Rennes, 2000 p. 347 <i>sq.</i>.</li>
        <li><a epub:type="footnote" href="#ref_44" id="note_44">44.</a>Les contre-méthodes hacker qui seront survolées plus loin ont même radicalisé cette tendance à transformer ARPANET en un système de réseautage social, notamment avec l’amélioration de systèmes de messagerie électronique, ce qui préfigura le devenir de l’Internet. On peut voir sur ce point <span class="auteur">Paloques-Berges</span>, Camille <cite>Entre trivialité et culture : une histoire de l’Internet vernaculaire. Émergence et médiations d’un folklore de réseau.</cite> Thèse de doctorat, Paris 8, Paris, 2011.</li>
        <li><a epub:type="footnote" href="#ref_45" id="note_45">45.</a><span class="auteur">Cohendet</span>, Patrick, Frédéric <span class="auteur">Créplet</span> et Olivier <span class="auteur">Dupouët</span> <a href="http://www.cairn.info/revue-francaise-de-gestion-2003-5-page-99.htm">Innovation organisationnelle, communautés de pratique et communautés épistémiques : le cas de Linux.</a> <cite>Revue française de gestion</cite>, 29 2003, Nr. 146.</li>
        <li><a epub:type="footnote" href="#ref_46" id="note_46">46.</a>C’était la vision du sociologue Ted Nelson, inventeur de l’hypertexte, de la bibliothèque universelle informatique et du projet Xanadu.</li>
        <li><a epub:type="footnote" href="#ref_47" id="note_47">47.</a>Alors qu’avec <abbr>CTSS</abbr>, il fallait un superviseur pour répartir la charge de calcul, ce qui constituait bien sûr une porte ouverte à une hiérarchie d’utilisateurs (entre ceux dont les accès à la machine étaient plus importants en raison de recherche en cours et ceux dont les accès à la machine consistaient à créer des programmes pour le plaisir ou pour des objectifs beaucoup trop abstraits pour les administrateurs). Voir sur ce point <span class="auteur">Garfinkel</span>, Simsin <cite lang="en" xml:lang="en">Architects of the Information Society: Thirty-Five Years of the Laboratory for Computer Science at Mit.</cite> <i lang="en" xml:lang="en">Cambridge, Mass.: <abbr>MIT</abbr> Press,</i> 1999.</li>
        <li><a epub:type="footnote" href="#ref_48" id="note_48">48.</a><span class="auteur">Roszak</span>, Théodore <cite lang="en" xml:lang="en">The Making of a Counter Culture: Reflections on the Technocratic Society and Its Youthful Opposition.</cite> <i lang="en" xml:lang="en">Berkeley, <abbr>CA</abbr>: University of California Press</i>, 1995.</li>
        <li><a epub:type="footnote" href="#ref_49" id="note_49">49.</a>On se reportera à la définition qu’en donne le sociologue du travail E. Wenger, résumée par C. Paloque-Berges : « [La communauté de pratique] désigne les moyens mis en œuvre dans les processus d’apprentissage collectifs autour d’un objet d’intérêt commun par des groupes socio-professionnels auto-organisés. Ces processus se divisent en deux phénomènes : la participation (les modes de sociabilité engagés dans la pratique collective) et la réification (la production d’un artefact), qui sont en constante interaction, et redéfinissent l’identité et l’activité de la communauté ». <span class="auteur">Paloques-Berges</span>, Camille <a href="http://www.cairn.info/resume.php?IDARTICLE=TDM0180111">La mémoire culturelle d’Internet : le folklore de Usenet</a>. Le Temps des médias, 18 2012, Nr. 1 p. 121.</li>
      </ul>
    </aside>

  </body>
</html>
